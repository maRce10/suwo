stop = 16)
}
if (X$repository[1] == "Macaulay Library") {
X$time <- ifelse(nchar(X$time) == 3, paste0(0, X$time), X$time)
X$time <- paste0(substr(X$time, 1, 2), ":", substr(X$time, 3, 4))
}
basic_colums <- c(
"repository",
"format",
"key",
"species",
"date",
"time",
"country",
"locality",
"latitude",
"longitude",
"file_url",
"file_extension"
)
# order so basic columns go first
non_basic_colms <- setdiff(names(X), basic_colums)
X <- X[, c(basic_colums, non_basic_colms)]
if (!all_data) {
# remove columns that are not basic
X <- X[, basic_colums]
}
## add attributes
X <- .add_attributes(
X = X,
term = rlang::call_args(call)$term,
format = format,
all_data = all_data,
call = call,
input_file = input_file
)
# drop additional levels
X <- droplevels(X)
return(X)
}
# get repo name from call
.repo_from_call <- function(x) {
switch(
strsplit(
x = as.character(x),
split = "(",
fixed = TRUE
)[[1]][1],
query_wikiaves = "Wikiaves",
query_xenocanto = "Xeno-Canto",
query_gbif = "GBIF",
query_inaturalist = "iNaturalist",
query_observation = "Observation",
query_macaulay = "Macaulay Library"
)
}
# add attributes to output data frames
.add_attributes <- function(X, term, format, all_data, input_file = NA, call) {
term <- gsub("%20", " ", term)
# Add a timestamp attribute
search_time <- Sys.time()
attr(X, "query_call") <- call
attr(X, "repository") <- .repo_from_call(call)
attr(X, "query_time") <- search_time
attr(X, "query_term") <- term
attr(X, "query_format") <- format
attr(X, "query_all_data") <- all_data
attr(X, "input_file(s)") <- input_file
attr(X, "suwo_version") <- utils::packageVersion("suwo")
return(X)
}
.color_text <- function(text,
as = c("success", "skip", "warning", "failure", "error")) {
if (.has_color()) {
unclass(cli::make_ansi_style(.suwo_style(as))(text))
} else {
text
}
}
.has_color <- function() {
cli::num_ansi_colors() > 1
}
.suwo_style <- function(type = c("success", "skip", "warning", "failure", "error")) {
type <- match.arg(type)
c(
success = "green",
skip = "blue",
warning = "magenta",
failure = "orange",
error = "orange"
)[[type]]
}
## function to split macaulay queries by year-month
.date_ranges <- function(x) {
x <- sort(x)
# current year as year.decimal
current_year <- as.numeric(format(Sys.Date(), "%Y"))
current_month <- as.numeric(format(Sys.Date(), "%m"))
unique_years <- floor(min(x)):floor(max(x))
# determine if has to be split by month
if (!all(x == floor(x))) {
# Calculate fraction of the year (0 = Jan, 1/12 â‰ˆ 0.0833 per month)
current_date <- current_year + (current_month) / 12
# filter dates in the future (higher than current date)
x <- x[x <= current_date]
if (current_year %in% unique_years) {
x <- c(x, current_date)
}
first_year <- min(floor(x))
last_year <- max(floor(x)) + 1 # add one to include the end of the year
# create df with all possible month year combinations
poss_month_year_df <- expand.grid(month = 1:12, year = first_year:last_year)
poss_month_year_df$year_decimal <-
poss_month_year_df$year + (poss_month_year_df$month - 1) / 12
date_list <- lapply(seq_along(x[-1]), function(y){
time_diff <- poss_month_year_df$year_decimal - x[y]
start <- poss_month_year_df[poss_month_year_df$year_decimal == poss_month_year_df$year_decimal[time_diff >= 0][1], ]
time_diff <- poss_month_year_df$year_decimal - x[y + 1]
end <- poss_month_year_df[poss_month_year_df$year_decimal == rev(poss_month_year_df$year_decimal[time_diff < 0])[1], ]
out <- cbind(start[, 1:2], end[, 1:2])
names(out) <- c("start_month", "start_year", "end_month", "end_year")
return(out)
}
)
dates_df <- do.call(rbind, date_list)
# expand rows that cross years
dates_list <- lapply(seq_len(nrow(dates_df)), function(i) {
Y <- dates_df[i, ]
if (Y$start_month > Y$end_month | Y$start_year < Y$end_year)
Y <- data.frame(
start_month = c(Y$start_month, 1),
start_year = c(Y$start_year, Y$start_year + 1),
end_month = c(12, Y$end_month),
end_year = c(Y$start_year, Y$start_year + 1)
)
return(Y)
})
dates_df <- do.call(rbind, dates_list)
} else {
# remove years above current year
unique_years <- unique_years[unique_years <= current_year]
dates_df <- data.frame(start_month = 1, start_year = x[-length(x)], end_month = 12, end_year = c(x[-c(1, length(x))] - 1, x[length(x)]), stringsAsFactors = FALSE)
}
return(dates_df)
}
# monitor if a new file is added
.monitor_new_files <- function(path, interval = 1) {
# Create initial snapshot
prev_snap <- utils::fileSnapshot(
path = path,
full.names = FALSE,
# Return only file names (not full paths)
pattern = "\\.csv$",
recursive = FALSE    # Don't check subfolders
)
while (TRUE) {
# Take new snapshot
current_snap <- utils::fileSnapshot(
path = path,
full.names = FALSE,
pattern = "\\.csv$",
recursive = FALSE
)
# Compare snapshots
changes <- utils::changedFiles(prev_snap, current_snap)
# Return only names of new files
if (length(changes$added) > 0) {
return(changes$added)  # Returns character vector of new file names
}
# Wait before checking again
Sys.sleep(interval)
# Update snapshot for next comparison
prev_snap <- current_snap
}
}
## function to check arguments
.check_arguments <- function(args) {
# create object to store check results
check_collection <- checkmate::makeAssertCollection()
### check arguments
if (!is.null(args$term)) {
checkmate::assert_multi_class(
x = args$term,
classes = c("character"),
add = check_collection,
.var.name = "term"
)
}
if (!is.null(args$format)) {
checkmate::assert_multi_class(
x = args$format,
classes = c("character"),
add = check_collection,
.var.name = "format"
)
}
if (!is.null(args$cores)) {
checkmate::assert_integerish(
args$cores,
add = check_collection,
lower = 1,
upper = parallel::detectCores(),
.var.name = "cores"
)
}
if (!is.null(args$pb)) {
checkmate::assert_logical(
x = args$pb,
len = 1,
add = check_collection,
.var.name = "pb"
)
}
if (!is.null(args$identified)) {
checkmate::assert_logical(
x = args$identified,
len = 1,
add = check_collection,
.var.name = "identified"
)
}
if (!is.null(args$verifiable)) {
checkmate::assert_logical(
x = args$verifiable,
len = 1,
add = check_collection,
.var.name = "verifiable"
)
}
if (!is.null(args$dataset)) {
if (!is.null(args$dataset)) {
checkmate::assert_multi_class(
x = args$dataset,
classes = c("character"),
add = check_collection,
.var.name = "dataset"
)
}
}
if (!is.null(args$all_data)) {
checkmate::assert_logical(
x = args$all_data,
len = 1,
add = check_collection,
.var.name = "all_data"
)
}
if (!is.null(args$token)) {
checkmate::assert_multi_class(
x = args$token,
classes = c("character"),
add = check_collection,
.var.name = "token"
)
}
if (!is.null(args$path)) {
if (!is.null(args$path)) {
checkmate::assert_directory(
x = args$path,
access = "r",
add = check_collection,
.var.name = "path"
)
}
}
if (!is.null(args$metadata)) {
checkmate::assert_multi_class(
x = args$metadata,
classes = c("data.frame"),
add = check_collection,
.var.name = "metadata"
)
}
return(check_collection)
}
# message when loading package
.onAttach <-
function(libname, pkgname) {
packageStartupMessage("\nPlease cite 'suwo' as: \n")
packageStartupMessage(
"Araya-Salas, M., & J. Elizondo-Calvo. 2023. suwo: access nature media repositories through R. R package version 0.1.0."
)
}
## check internet
# gracefully fail if internet resource is not available
.try_GET <- function(x, ...) {
tryCatch(
httr::GET(url = x, httr::timeout(10), agent = "suwo (https://github.com/maRce10/suwo)"),
error = function(e)
conditionMessage(e),
warning = function(w)
conditionMessage(w)
)
}
.is_response <- function(x) {
class(x) == "response"
}
.check_internet_resource <- function(url, skip.error = FALSE) {
output <- "OK"
# First check internet connection
if (!curl::has_internet()) {
.message(x = "No internet connection.", color = "cyan")
output <- "not_OK"
} else {
# Then try for timeout problems
resp <- .try_GET(url)
if (!.is_response(resp)) {
.message(x = resp, color = "cyan")
output <- "not_OK"
} else {
if (httr::http_error(resp) & !skip.error) {
httr::message_for_status(resp)
output <- "not_OK"
}
}
}
return(output)
}
# usa esta funcion internamente para sacar los rangos
.date_ranges(x = c(1976, 2020, 2022, 2024, 2025, 2026))
.date_ranges(x = seq(2020, 2026, length.out = 6))
remove.packages("suwo")
remotes::install_github("maRce10/suwo")
library(suwo)
remove.packages("suwo")
remotes::install_github("maRce10/suwo")
library(suwo)
install.packages("mime")
source("~/Dropbox/R_package_testing/suwo/R/check_gbif_datasets.R")
# Check internet connection
response <- try(httr::GET("https://www.gbif.org"), silent = TRUE)
content_text <- httr::content(response, "text", encoding = "UTF-8"
response
content_text <- httr::content(response, "text", encoding = "UTF-8")
content_text
grepl("Could not connect to the database", content_text)
csv_url <- "https://api.gbif.org/v1/dataset/search/export?format=CSV&"
csv_response <- try(httr::GET(csv_url), silent = TRUE)
csv_response
read.csv("https://api.gbif.org/v1/dataset/search/export?format=CSV&")
a <- read.csv("https://api.gbif.org/v1/dataset/search/export?format=CSV&")
str(a)
tf <- tempfile()
tf
download.file("https://api.gbif.org/v1/dataset/search/export?format=CSV&",destfile = tf)
a
str(a)
View(a)
Sys.Date()
file_name <- paste("gbif_datasets_", Sys.Date(), ".csv")
file_name
# csv_response <- try(httr::GET(csv_url), silent = TRUE)
file_name <- paste0("gbif_datasets_", Sys.Date(), ".csv")
file_name <- file.path(path, file_name)
source("~/Dropbox/R_package_testing/suwo/R/check_gbif_datasets.R")
a <- check_gbif_datasets()
source("~/Dropbox/R_package_testing/suwo/R/check_gbif_datasets.R")
a
source("~/Dropbox/R_package_testing/suwo/R/check_gbif_datasets.R")
a <- check_gbif_datasets()
source("~/Dropbox/R_package_testing/suwo/R/check_gbif_datasets.R")
source("~/Dropbox/R_package_testing/suwo/R/check_gbif_datasets.R")
a <- check_gbif_datasets()
source("~/Dropbox/R_package_testing/suwo/R/check_gbif_datasets.R")
cli::cli_text(paste0("The GBIF dataset info was save in  {.file ", file_name, "}"))
cli::cli_text(paste0("The GBIF dataset info was save in  {.file ", path, "}"))
cli::cli_text(paste0("The GBIF dataset info was save in  {.file ", ".", "}"))
cli::cli_text(paste0("The GBIF dataset info was save in  {.file ", normalizePath("."), "}"))
cli::cli_text(paste0("The GBIF dataset info was save in  {.file ", ".", "}"))
source("~/Dropbox/R_package_testing/suwo/R/check_gbif_datasets.R")
source("~/Dropbox/R_package_testing/suwo/R/check_gbif_datasets.R")
#run document twice
devtools::document(".")
devtools::document(".")
test <- query_gbif("agalychnis lemur", format = "sound")
test <- query_gbif("Turdus grayi", format = "sound")
test2 <- query_macaulay(term = "turdus grayi", "sound")
test2 <- query_macaulay(term = "Turdus iliacus", "sound")
test2 <- query_macaulay(term = "Turdus iliacus", "sound")
#run document twice
devtools::document(".")
test <- query_xenocanto("sp:"Larus fucus"",key = "74514db996296de720964827e4d727bbeefbaaa3")
test <- query_xenocanto("sp:Larus fucus",key = "74514db996296de720964827e4d727bbeefbaaa3")
#run document twice
devtools::document(".")
test <- query_xenocanto("sp:Larus fucus",key = "74514db996296de720964827e4d727bbeefbaaa3")
devtools::document(".")
test <- query_xenocanto("sp:Larus fucus",key = "74514db996296de720964827e4d727bbeefbaaa3")
#run document twice
devtools::document(".")
test <- query_xenocanto("sp:Larus fucus",key = "74514db996296de720964827e4d727bbeefbaaa3")
test <- query_xenocanto("sp:Larus fuscus",key = "74514db996296de720964827e4d727bbeefbaaa3")
#run document twice
devtools::document(".")
test <- query_xenocanto("sp:Larus fuscus",key = "74514db996296de720964827e4d727bbeefbaaa3")
#run document twice
devtools::document(".")
test <- query_xenocanto("sp:Larus fuscus",key = "74514db996296de720964827e4d727bbeefbaaa3")
View(test)
devtools::document(".")
answ<- query_xenocanto(species="Turdus grayi",key = "74514db996296de720964827e4d727bbeefbaaa3")
View(answ)
devtools::document(".")
answ<- query_xenocanto(term="Turdus grayi",key = "74514db996296de720964827e4d727bbeefbaaa3")
View(answ)
# Crear la tabla
datos <- matrix(c(0, 2,
8, 0,
1, 0),
nrow = 2,
byrow = TRUE)
colnames(datos) <- c("Grapsidae", "HermitaÃ±o", "Coleoptero_Trox")
rownames(datos) <- c("Con_Luz", "Sin_Luz")
# Mostrar tabla
datos
# Totales
total <- matrix(c(9, 2), nrow = 2, byrow = TRUE)
rownames(total) <- c("Con_Luz", "Sin_Luz")
colnames(total) <- c("Organismos")
# Si solo quieres ver diferencia de totales entre condiciones:
chisq.test(total)
# Pero como es 2x1, mejor Fisher:
fisher.test(total)
# Datos
observado <- c(1, 14, 37)
# Supongamos distribuciÃ³n esperada uniforme
esperado <- rep(sum(observado)/3,3)
# Chi-cuadrado de bondad de ajuste
chisq.test(x=observado, p=rep(1/3,3))
pkgcheck()
## pckgcheck
x <- pkgcheck::pkgcheck(".")
#run document twice
devtools::document(".")
pkgcheck::pkgcheck(".")
install.packages("pkgcheck")
pkgcheck::pkgcheck(".")
remotes::install_github("ropensci-review-tools/pkgcheck")
# devtools::install()
remotes::install_github("ropensci-review-tools/pkgcheck")
pkgcheck::pkgcheck(".")
# devtools::install()
remotes::install_github("ropensci-review-tools/pkgcheck")
install.packages("devtools")
# devtools::install()
remotes::install_github("ropensci-review-tools/pkgcheck")
pkgbuild::check_build_tools(debug = TRUE)
# devtools::install()
remotes::install_github("ropensci-review-tools/pkgcheck")
Sys.which("make")
Sys.which("make")
# devtools::install()
remotes::install_github("ropensci-review-tools/pkgcheck")
# get pakage name
pkg <- strsplit(y, "/")[[1]]
# devtools::install()
remotes::install_github("ropensci-review-tools/pkgcheck")
install.packages("devtools")
# devtools::install()
remotes::install_github("ropensci-review-tools/pkgcheck")
pkgs <- c("remotes", "curl", "RCurl", "jsonlite", "crayon", "devtools", "leaflet", "maps", "pkgcheck", "pkgstats", "testthat", "styler", "cli", "beepr", "RecordLinkage", "getPass")
# install/ load packages
out <- lapply(pkgs, function(y) {
# get pakage name
pkg <- strsplit(y, "/")[[1]]
pkg <- pkg[length(pkg)]
# check if installed, if not then install
if (!pkg %in% installed.packages()[,"Package"])  {
if (grepl("/", y))  remotes::install_github(y, force = TRUE) else
install.packages(y)
}
# load package
a <- try(require(pkg, character.only = T), silent = T)
if (!a) remove.packages(pkg)
})
rm(list = ls())
# install ctags
# first run in terminal: sudo apt install lsb-core
# then run this with sudo privilege
# ctags_install(bin_dir = NULL, sudo = TRUE)
# load_all()
pkgcheck::pkgcheck(".")
install.packages ("pkgstats")
ctags_test ()
remotes::install_github ("ropensci-review-tools/pkgstats")
pak::pkg_install ("ropensci-review-tools/pkgstats")
system("ctags --version")
pkgcheck::pkgcheck(".")
Sys.which("ctags")
system("ctags --version", intern = TRUE)
pkgstats::pkgstats(".")
cat('PATH="E:\\ctags;%PATH%"', file = file.path(Sys.getenv("USERPROFILE"), ".Renviron"), append = TRUE, sep = "\n")
pkgcheck::pkgcheck(".")
Sys.which("ctags")
Sys.setenv(PATH = paste("C:\\ctags", Sys.getenv("PATH"), sep = ";"))
Sys.which("ctags")
pkgcheck::pkgcheck(".")
options(pkgstats.ctags = "E:\\ctags\\ctags.exe")
pkgcheck::pkgcheck(".")
options(pkgstats.ctags = "E:\\ctags\\ctags.exe")
cat('options(pkgstats.ctags = "E:\\\\ctags\\\\ctags.exe")',
file = file.path(Sys.getenv("USERPROFILE"), ".Rprofile"),
append = TRUE, sep = "\n")
pkgcheck::pkgcheck(".")
system2("E:\\ctags\\ctags.exe", args = "--version", stdout = TRUE, stderr = TRUE)
pkgstats:::ctags_okay()
# Force pkgstats to believe ctags is fine
assignInNamespace(
x = "require_ctags",
value = function(...) TRUE,
ns = "pkgstats"
)
