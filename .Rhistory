if(is.null(dataset)) "" else dataset_key,
"scientificName=", term, "&media_type=",
type
)
base.srch.pth <- jsonlite::fromJSON(srch_trm)
# get total number of pages
offsets <- (seq_len(ceiling(base.srch.pth$count / base.srch.pth$limit)) - 1) * 300
query_output_list <- pblapply_sw_int(offsets, cl = 1, pbar = pb, function(i)
{
query_output <- jsonlite::fromJSON(paste0(srch_trm, "&offset=", i))
# format as list of data frame
query_output$results <- lapply(seq_len(nrow(query_output$results)), function(u) {
x <- query_output$results[u, ]
# media_df <- do.call(rbind, media_list)
media_df <- do.call(rbind, x$media)
# select type
media_df <- media_df[media_df$type == type,]
# fix identifier column name
names(media_df)[names(media_df) == "identifier"] <- "URL"
names(media_df) <- paste0("media-", names(media_df))
# remove lists
x <- x[!sapply(x, is.list)]
# make it data frame
X_df <- data.frame(t(unlist(x)))
# add media details
X_df <- cbind(X_df, media_df)
return(X_df)
})
# get common names to all data frames in X
common_names <- unique(unlist(lapply(query_output$results, names)))
# add missing columns to all data frames in X
query_output$results <- lapply(query_output$results, function(e){
nms <- names(e)
if (length(nms) != length(common_names))
for (o in common_names[!common_names %in% nms]) {
e <-
data.frame(e,
NA,
stringsAsFactors = FALSE,
check.names = FALSE)
names(e)[ncol(e)] <- o
}
return(e)
})
# all results in a single data frame
output_df <- do.call(rbind, query_output$results)
output_df$page <- i
return(output_df)
})
# get common names to all data frames in X
gbifcolumns <- common_names <- unique(unlist(lapply(query_output_list, names)))
term = "hirundo rustica"
#format JSON
term <- gsub(" ", "%20", term)
#initialize search
get_ids <-
jsonlite::fromJSON(paste0(
"https://www.wikiaves.com.br/getTaxonsJSON.php?term=",
term
))
# make it a data frame
get_ids <- as.data.frame(t(sapply(get_ids, unlist)))
get_ids$total_registers <-sapply(1:nrow(get_ids), function(u)
as.numeric(jsonlite::fromJSON(
paste0(
"https://www.wikiaves.com.br/getRegistrosJSON.php?tm=",
if (type == "photo")
"f" else
"s",
"&t=s&s=",
get_ids$id[u],
"&o=mp&p=1"
)
)$registros$total))
# get number of pages (20 is the default number of registers per page)
get_ids$pages <- ceiling(get_ids$total_registers / 20)
# remove those rows with no pages (only needed when many species are returned)
get_ids <- get_ids[get_ids$pages > 0, ]
id_by_page_list <- lapply(1:nrow(get_ids), function(x){
X <- get_ids[x, ]
out_df <- data.frame(id = X$id, page = 1:X$pages)
})
id_by_page_df <- do.call(rbind, id_by_page_list)
# loop over pages
query_output_list <- pblapply_sw_int(1:nrow(id_by_page_df), cl = cl, pbar = pb, function(i)
{
query_output <-
jsonlite::fromJSON(
paste0(
"https://www.wikiaves.com.br/getRegistrosJSON.php?tm=",
if (type == "photo")
"f" else
"s",
"&t=",
"s",
"&s=",
id_by_page_df$id[i],
"&o=mp&p=",
id_by_page_df$page[i]
)
)
# make it a data frame
output_df <-
as.data.frame(t(sapply(
query_output$registros$itens, unlist
)))
# fix link
output_df$link <- gsub("#", "", as.character(output_df$link))
return(output_df)
})
# rename output columns
wikiavescolumns <- names_df <- data.frame(old = c("id", "tipo", "id_usuario", "sp.id", "sp.nome", "sp.nvt", "sp.idwiki", "autor", "perfil", "data", "is_questionada", "local", "idMunicipio", "coms", "likes", "vis", "link", "dura", "repository"), new = c("record.id", "media.type", "user.id", "sp.id", "scientific.name", "common.name", "repository.id", "author", "user.name", "date", "verified", "location", "location.id", "comments", "likes", "visualizations", "file_url", "duration", "repository"))
#initialize search
q <-
jsonlite::fromJSON(paste0(
"https://www.xeno-canto.org/api/2/recordings?query=",
term
))
nms <-
c(
"id",
"gen",
"sp",
"ssp",
"en",
"rec",
"cnt",
"loc",
"lat",
"lng",
"type",
"file",
"lic",
"url",
"q",
"time",
"date"
)
records_list <-
pblapply_sw_int(
pbar = pb,
X = 1:q$numPages,
cl = cl,
FUN = function(y)
{
#search for each page
a <-
rjson::fromJSON(
file = paste0(
"https://www.xeno-canto.org/api/2/recordings?query=",
term,
"&page=",
y
)
)
#put together as data frame
d <-
lapply(1:length(a$recordings), function(z)
data.frame(t(unlist(
a$recordings[[z]]
))))
d2 <- lapply(d,  function(x)
{
if (!all(nms %in% names(x))) {
dif <- setdiff(nms, names(x))
mis <- rep(NA, length(dif))
names(mis) <- dif
return(cbind(x, t(mis)))
}
return(x)
})
# determine all column names in all pages
cnms <- unique(unlist(lapply(d2, names)))
# add columns that are missing to each selection table
d3 <- lapply(d2, function(X)
{
nms <- names(X)
if (length(nms) != length(cnms))
for (i in cnms[!cnms %in% nms]) {
X <-
data.frame(X,
NA,
stringsAsFactors = FALSE,
check.names = FALSE)
names(X)[ncol(X)] <- i
}
return(X)
})
e <- do.call(rbind, d3)
return(e)
}
)
# determine all column names in all pages
cnms <- unique(unlist(lapply(records_list, names)))
# add columns that are missing to each selection table
records_list2 <- lapply(records_list, function(X)
{
nms <- names(X)
if (length(nms) != length(cnms))
for (i in cnms[!cnms %in% nms]) {
X <-
data.frame(X,
NA,
stringsAsFactors = FALSE,
check.names = FALSE)
names(X)[ncol(X)] <- i
}
return(X)
})
# save results in a single data frame
results <- do.call(rbind, records_list2)
# convert factors to characters
indx <- sapply(results, is.factor)
results[indx] <- lapply(results[indx], as.character)
#order columns
results <- results[, order(match(names(results), nms))]
names(results)[match(
c(
"id",
"gen",
"sp",
"ssp",
"en",
"rec",
"cnt",
"loc",
"lat",
"lng",
"alt",
"type",
"file",
"lic",
"url",
"q",
"length",
"time",
"date",
"uploaded",
"rmk",
"bird.seen",
"playback.used"
),
names(results)
)] <-
c(
"record.id",
"genus",
"specific.epithet",
"subspecies",
"english.name",
"recordist",
"country",
"locality",
"latitude",
"longitude",
"altitude",
"vocalization.type",
"audio_file",
"license",
"url",
"quality",
"length",
"time",
"date",
"uploaded",
"remarks",
"bird.seen",
"playback.used"
)[which(
c(
"id",
"gen",
"sp",
"ssp",
"en",
"rec",
"cnt",
"loc",
"lat",
"lng",
"alt",
"type",
"file",
"lic",
"url",
"q",
"length",
"time",
"date",
"uploaded",
"rmk",
"bird.seen",
"playback.used"
) %in% names(results)
)]
# rename also columns
names(results) <- gsub("also", "other.species", names(results))
# rename
names(results) <- gsub("sono.", "spectrogram.", names(results))
#Add repository ID
results$repository <- "XC"
#remove duplicates
results <- results[!duplicated(results$record.id),]
#Rename record.id
colnames(results)[colnames(results) == "record.id"] ="file_url"
xenocolumns <- common_names <- unique(unlist(lapply(results, names)))
xenocolumns
results
xenocolumns <- colnames(results)
xenocolumns
install.packages("rowr")
mxn <- max(nrow(inatcolumns), nrow(gbifcolumns))
inatcolumns
gbifcolumns
wikiavescolumns
cbind(inatcolumns,gbifcolumns)
library(rowr)
install.packages("zoo")
library(zoo)
rollapply(inatcolumns,gbifcolumns,na.fill=TRUE)
# rename output columns
wikiavescolumns <- names_df <- data.frame(c("record.id", "media.type", "user.id", "sp.id", "scientific.name", "common.name", "repository.id", "author", "user.name", "date", "verified", "location", "location.id", "comments", "likes", "visualizations", "file_url", "duration", "repository"))
wikiavescolumns
# rename output columns
wikiavescolumns <- names_df <- data.frame("record.id", "media.type", "user.id", "sp.id", "scientific.name", "common.name", "repository.id", "author", "user.name", "date", "verified", "location", "location.id", "comments", "likes", "visualizations", "file_url", "duration", "repository")
wikiavescolumns
#initialize search
get_ids <-
jsonlite::fromJSON(paste0(
"https://www.wikiaves.com.br/getTaxonsJSON.php?term=",
term
))
# make it a data frame
get_ids <- as.data.frame(t(sapply(get_ids, unlist)))
get_ids$total_registers <-sapply(1:nrow(get_ids), function(u)
as.numeric(jsonlite::fromJSON(
paste0(
"https://www.wikiaves.com.br/getRegistrosJSON.php?tm=",
if (type == "photo")
"f" else
"s",
"&t=s&s=",
get_ids$id[u],
"&o=mp&p=1"
)
)$registros$total))
# get number of pages (20 is the default number of registers per page)
get_ids$pages <- ceiling(get_ids$total_registers / 20)
# remove those rows with no pages (only needed when many species are returned)
get_ids <- get_ids[get_ids$pages > 0, ]
id_by_page_list <- lapply(1:nrow(get_ids), function(x){
X <- get_ids[x, ]
out_df <- data.frame(id = X$id, page = 1:X$pages)
})
id_by_page_df <- do.call(rbind, id_by_page_list)
# loop over pages
query_output_list <- pblapply_sw_int(1:nrow(id_by_page_df), cl = cl, pbar = pb, function(i)
{
query_output <-
jsonlite::fromJSON(
paste0(
"https://www.wikiaves.com.br/getRegistrosJSON.php?tm=",
if (type == "photo")
"f" else
"s",
"&t=",
"s",
"&s=",
id_by_page_df$id[i],
"&o=mp&p=",
id_by_page_df$page[i]
)
)
# make it a data frame
output_df <-
as.data.frame(t(sapply(
query_output$registros$itens, unlist
)))
# fix link
output_df$link <- gsub("#", "", as.character(output_df$link))
return(output_df)
})
# put in a data frame
query_output_df <- do.call(rbind, query_output_list)
# rename rows
rownames(query_output_df) <- 1:nrow(query_output_df)
# change jpg to mp3 in links
if (type == "audio")
query_output_df$link <-
gsub("\\.jpg$", ".mp3",  query_output_df$link)
# add repository
query_output_df$repository <- "wikiaves"
# remove weird columns
query_output_df$por <- query_output_df$grande <- query_output_df$enviado <- NULL
# flip verified
query_output_df$is_questionada <- !as.logical(query_output_df$is_questionada)
#fix media type
query_output_df$tipo <- type
wikiavescolumns <- colnames(query_output_df)
wikiavescolumns
xenocolumns
inat_list <- as.list(inatcolumns)
gbif_list <- as.list(gbifcolumns)
wikiaves_list <- as.list(wikiavescolumns)
xenocant_list <- as.list(xenocolumns)
inat_list
View(inat_list)
inat_list <- as.character(inatcolumns)
inat_list
View(inat_list)
inat_list
inat_list <- as.data.frame.list(inatcolumns)
View(inat_list)
View(inatcolumns)
inatcolumns
View(inatcolumns)
str(inatcolumns)
as.data.frame(inatcolumns)
View(inatcolumns)
View(xenocolumns)
inat_list <- as.data.frame(inatcolumns)
gbif_list <- as.data.frame(gbifcolumns)
wikiaves_list <- as.data.frame(wikiavescolumns)
xenocant_list <- as.data.frame(xenocolumns)
View(inat_list)
cbind.data.frame(inat_list,gbif_list)
cbind.data.frame(inat_list,gbif_list,na.fill())
cbind.data.frame(inat_list,gbif_list,na.fill=TRUE)
library(plyr)
rbindd <- rbind.fill(inat_list,gbif_list)
rbindd
rbindd <- cbind.fill(inat_list,gbif_list)
rbindd <- rbind.fill(inat_list+gbif_list)
rbindd <- rbind.fill(inat_list,gbif_list)
inat_list <- as.data.frame(inatcolumns)
gbif_list <- as.data.frame(gbifcolumns)
wikiaves_list <- as.data.frame(wikiavescolumns)
xenocant_list <- as.data.frame(xenocolumns)
write.csv(inat_list, ~/Dropbox/R_package_testing/suwo/inatcolumns.csv, row.names=FALSE)
write.csv(inat_list, /Dropbox/R_package_testing/suwo/inatcolumns.csv, row.names=FALSE)
write.csv(inat_list,Dropbox/R_package_testing/suwo/inatcolumns.csv, row.names=FALSE)
write.csv(inat_list,"~/Dropbox/R_package_testing/suwo/Rinatcolumns.csv", row.names=FALSE)
write.csv(gbif_list,"~/Dropbox/R_package_testing/suwo/Rgbifcolumns.csv", row.names=FALSE)
write.csv(wikiaves_list,"~/Dropbox/R_package_testing/suwo/Rwikiavescolumns.csv", row.names=FALSE)
write.csv(xenocant_list,"~/Dropbox/R_package_testing/suwo/Rxenocolumns.csv", row.names=FALSE)
#format JSON
term <- gsub(" ", "%20", term)
source("~/Dropbox/R_package_testing/suwo/R/internal_functions.R")
source("~/Dropbox/R_package_testing/suwo/R/query_xenocanto.R")
source("~/Dropbox/R_package_testing/suwo/R/query_wikiaves.R")
source("~/Dropbox/R_package_testing/suwo/R/query_wikiaves.R")
source("~/Dropbox/R_package_testing/suwo/R/query_gbif.R")
inial <- query_gbif(term = "turdus grayi", type = "still image", all_data = TRUE)
source("~/Dropbox/R_package_testing/suwo/R/query_gbif.R")
inial <- query_gbif(term = "turdus grayi", type = "still image", all_data = TRUE)
inial <- query_gbif(term = "turdus grayi", type = "still image")
source("~/Dropbox/R_package_testing/suwo/R/query_gbif.R")
inial <- query_gbif(term = "turdus grayi", type = "still image")
source("~/Dropbox/R_package_testing/suwo/R/query_xenocanto.R")
ini <- query_xenocanto(term = "hirundo rustica", all_data = TRUE)
source("~/Dropbox/R_package_testing/suwo/R/query_xenocanto.R")
source("~/Dropbox/R_package_testing/suwo/R/query_inaturalist.R")
inial <- query_inaturalist(term = "agalychnis lemur", type = "still image", all_data = T)
source("~/Dropbox/R_package_testing/suwo/R/query_inaturalist.R")
inial <- query_inaturalist(term = "agalychnis lemur", type = "still image", all_data = T)
source("~/Dropbox/R_package_testing/suwo/R/query_inaturalist.R")
inial <- query_inaturalist(term = "agalychnis lemur", type = "still image", all_data = T)
inial <- query_inaturalist(term = "agalychnis lemur", type = "still image", all_data = F)
View(inial)
inial <- query_inaturalist(term = "agalychnis lemur", type = "still image", all_data = T)
View(inial)
source("~/Dropbox/R_package_testing/suwo/R/query_inaturalist.R")
source("~/Dropbox/R_package_testing/suwo/R/query_inaturalist.R")
source("~/Dropbox/R_package_testing/suwo/R/query_gbif.R")
inial <- query_gbif(term = "agalychnis lemur", type = "still image", all_data = T)
source("~/Dropbox/R_package_testing/suwo/R/query_gbif.R")
inial <- query_gbif(term = "agalychnis lemur", type = "still image", all_data = T)
inial <- query_gbif(term = "agalychnis lemur", type = "still image", all_data = F)
source("~/Dropbox/R_package_testing/suwo/R/query_gbif.R")
inial <- query_gbif(term = "agalychnis lemur", type = "still image", all_data = F)
source("~/Dropbox/R_package_testing/suwo/R/query_gbif.R")
inial <- query_gbif(term = "agalychnis lemur", type = "still image", all_data = T)
source("~/Dropbox/R_package_testing/suwo/R/query_gbif.R")
inial <- query_gbif(term = "agalychnis lemur", type = "still image", all_data = F)
source("~/Dropbox/R_package_testing/suwo/R/query_gbif.R")
inial <- query_gbif(term = "agalychnis lemur", type = "still image", all_data = F)
source("~/Dropbox/R_package_testing/suwo/R/query_gbif.R")
inial <- query_gbif(term = "agalychnis lemur", type = "still image", all_data = F)
source("~/Dropbox/R_package_testing/suwo/R/query_gbif.R")
inial <- query_gbif(term = "agalychnis lemur", type = "still image", all_data = F)
View(inial)
source("~/Dropbox/R_package_testing/suwo/R/query_gbif.R")
source("~/Dropbox/R_package_testing/suwo/R/query_gbif.R")
source("~/Dropbox/R_package_testing/suwo/R/query_wikiaves.R")
source("~/Dropbox/R_package_testing/suwo/R/query_gbif.R")
source("~/Dropbox/R_package_testing/suwo/R/query_xenocanto.R")
source("~/Dropbox/R_package_testing/suwo/R/query_wikiaves.R")
source("~/Dropbox/R_package_testing/suwo/R/query_xenocanto.R")
source("~/Dropbox/R_package_testing/suwo/R/query_inaturalist.R")
source("~/Dropbox/R_package_testing/suwo/R/query_wikiaves.R")
inial <- query_wikiaves(term = "phraetornis guy", type = "still image", all_data = F)
inial <- query_wikiaves(term = "phaetornis guy", type = "still image", all_data = F)
inial <- query_wikiaves(term = "phaetornis", type = "still image", all_data = F)
inial <- query_wikiaves(term = "guy", type = "still image", all_data = F)
View(inial)
source("~/Dropbox/R_package_testing/suwo/R/query_wikiaves.R")
inial <- query_wikiaves(term = "guy", type = "still image", all_data = F)
View(inial)
source("~/Dropbox/R_package_testing/suwo/R/query_wikiaves.R")
library(rcurl)
install.packages(rcurl)
library(curl)
