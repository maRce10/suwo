h_sarapiquensis = h_sarapiquensis,
p_striigularis = p_striigularis,
d_holocanthus = d_holocanthus
)
sapply(testing_metadata, names)
usethis::use_data(
ml_taxon_code,
merged_metadata,
testing_metadata,
internal = TRUE,
overwrite = TRUE
)
### create function description table for vignette
metadata_list <- testing_metadata
Repository <- vapply(
metadata_list,
function(x) {
x[1, "repository"]
},
character(1)
)
Repository[Repository == "Wikiaves"] <- "WikiAves"
names(metadata_list) <- tolower(Repository)
Function <- c(
gbif = "query_gbif",
inaturalist = "query_inaturalist",
`macaulay library` = "query_macaulay",
observation = "query_observation",
wikiaves = "query_wikiaves",
`xeno-canto` = "query_xenocanto"
)
Function <- Function[match(names(metadata_list), names(Function))]
file_types <- vapply(
Function,
function(x) {
paste(formals(get(x))$format, collapse = ", ")
},
FUN.VALUE = character(1)
)
file_types <- gsub("c, ", "", file_types)
file_types[Function == "query_xenocanto"] <- "sound"
file_types <- gsub("getOption,|suwo_format, c", "", file_types)
# remove c(, ) and " from file_types
file_types <- gsub("\\(|\\)|\"", "", file_types)
urls <- c(
gbif = "https://www.gbif.org/",
inaturalist = "https://www.inaturalist.org/",
`macaulay library` = "https://www.macaulaylibrary.org/",
observation = "https://observation.org/",
wikiaves = "https://www.wikiaves.com.br/",
`xeno-canto` = "https://www.xeno-canto.org/"
)
urls <- urls[match(names(metadata_list), names(urls))]
token <- c(
gbif = "No",
inaturalist = "No",
`macaulay library` = "No",
observation = "Yes",
wikiaves = "No",
`xeno-canto` = "Yes"
)
token <- token[match(names(metadata_list), names(token))]
tax_level <- c(
gbif = "Species",
inaturalist = "Species",
`macaulay library` = "Species",
observation = "Species",
wikiaves = "Species",
`xeno-canto` = "Species, subspecies, genus, family, group"
)
tax_level <- tax_level[match(names(metadata_list), names(tax_level))]
geo_cover <- c(
gbif = "Global",
inaturalist = "Global",
`macaulay library` = "Global",
observation = "Global",
wikiaves = "Brazil",
`xeno-canto` = "Global"
)
geo_cover <- geo_cover[match(names(metadata_list), names(geo_cover))]
tax_coverage <- c(
gbif = "All life",
inaturalist = "All life",
`macaulay library` = "Mostly birds but also other vertebrates and
invertebrates",
observation = NA,
wikiaves = "Birds",
`xeno-canto` = "Birds, frogs, non-marine mammals and grasshoppers"
)
tax_coverage <- tax_coverage[match(names(metadata_list), names(tax_coverage))]
other <- c(
gbif = "Specify query by data base",
inaturalist = "",
`macaulay library` = "Interactive",
observation = "",
wikiaves = "",
`xeno-canto` = "Specify query by taxonomy, geographic range and dates"
)
other <- other[match(names(metadata_list), names(other))]
colnames <- lapply(metadata_list, names)
colnames <- lapply(colnames, function(x) {
setdiff(x, suwo:::.format_query_output(only_basic_columns = TRUE))
})
additional_data <- vapply(
colnames,
function(x) {
paste(x, collapse = ", ")
},
FUN.VALUE = character(1)
)
additional_data <- additional_data[match(
names(metadata_list),
names(additional_data)
)]
additional_data
query_summary <- data.frame(
Function = Function,
Repository = Repository,
`URL link` = urls,
`File types` = file_types,
`Requires api key` = token,
`Taxonomic level` = tax_level,
`Geographic coverage` = geo_cover,
`Taxonomic coverage` = tax_coverage,
`Additional data` = additional_data,
`Other features` = other,
stringsAsFactors = FALSE,
check.names = FALSE
)
# remove duplicates
query_summary <- query_summary[!duplicated(query_summary$Repository), ]
query_summary <- query_summary[order(query_summary$Repository), ]
# Save it as a txt file
write.table(
query_summary,
"./vignettes/query_function_summary.txt",
row.names = FALSE,
sep = "\t"
)
library(knitr)
library(suwo)
source("~/Dropbox/R_package_testing/suwo/R/query_macaulay.R")
source("~/Dropbox/R_package_testing/suwo/R/internal_functions.R")
load("~/Dropbox/R_package_testing/suwo/R/sysdata.rda")
# Create custom printing method
.print_df <- function(x, highlight = NULL, ...) {
kbl <- kableExtra::kable(
head(as.data.frame(x)),
align = "c",
row.names = FALSE,
format = "html",
escape = FALSE
)
if (!is.null(highlight))
kbl <- kableExtra::column_spec(
kbl,
column = which(names(x) %in% highlight),
background = "#ccebff",
bold = TRUE
)
kbl <- kableExtra::kable_styling(kbl, bootstrap_options = "striped",
font_size = 14)
kbl <- kableExtra::scroll_box(kbl, width = "100%", height = "300px")
asis_output(kbl)
}
# Register custom data frame print method
registerS3method("knit_print", "data.frame", .print_df)
# Global chunk options
knitr::opts_chunk$set(
fig.width = 5,
fig.height = 3.5,
dpi = 70,
comment = "",
out.width = "80%",
fig.align = "center",
message = TRUE,
warning = TRUE
)
options(width = 100, max.print = 100, suwo_pb = FALSE)
dir_tree <- function(path) {
cat(gsub("\\[[0-9;]*[mK]", "", capture.output(fs::dir_tree(path))),
sep = "\n")
}
library(knitr)
library(kableExtra)
query_summary <- read.table("query_function_summary.txt",
stringsAsFactors = FALSE,
header = TRUE)
library(knitr)
library(kableExtra)
query_summary <- read.table("./vignette/query_function_summary.txt",
stringsAsFactors = FALSE,
header = TRUE)
library(knitr)
library(kableExtra)
query_summary <- read.table("./vignettes/query_function_summary.txt",
stringsAsFactors = FALSE,
header = TRUE)
# replace . with empty space in column names
names(query_summary) <- gsub("\\.", " ", names(query_summary))
query_summary$`URL link` <- kableExtra::cell_spec(query_summary$`URL link`,
"html",
link = query_summary$`URL link`,
new_tab = TRUE)
query_summary$Function <- kableExtra::cell_spec(
query_summary$Function,
"html",
link = paste0(
"https://marce10.github.io/suwo/reference/",
query_summary$Function,
".html"
),
new_tab = TRUE
)
query_summary[, names(query_summary) != "Additional data"] |>
kableExtra::kbl(
caption =
"Table 1: Summary of query functions and the associated repositories.",
format = "html",
escape = FALSE,
row.names = FALSE
) |>
kableExtra::kable_styling(
bootstrap_options = c("striped", "hover", "condensed", "responsive"),
full_width = FALSE,
position = "left"
)
query_summary[, c("Function", "Additional data")] |>
kableExtra::kbl(
caption = "Table 2: Additional metadata per query function.",
format = "html",
escape = FALSE,
row.names = FALSE
) |>
kableExtra::kable_styling(
bootstrap_options = c("striped", "hover", "condensed", "responsive"),
full_width = FALSE,
position = "left"
)
# initial query
c_eisentrauti <- query_inaturalist(species = "Chorthippus eisentrauti")
head(c_eisentrauti, 4)
# exclude new observations (simulate old data)
old_c_eisentrauti <-
c_eisentrauti[c_eisentrauti$date <= "2024-12-31" | is.na(c_eisentrauti$date),
]
old_c_eisentrauti
nrow(old_c_eisentrauti)
# update "old" data
upd_c_eisentrauti <- update_metadata(metadata = old_c_eisentrauti)
# compare number of records
nrow(c_eisentrauti) == nrow(upd_c_eisentrauti)
# Execute the code from the vignette
knitr::knit("vignettes/suwo.Rmd.orig", output = "vignettes/suwo.Rmd")
# query GBIF for Amanita zambiana images
a_zam <- query_gbif(species = "Amanita zambiana", format = "image")
# create folder for images
out_folder <- file.path(tempdir(), "amanita_zambiana")
dir.create(out_folder)
# download media files to a temporary directory
azam_files <- download_media(metadata = a_zam, path = out_folder)
# grDevices::jpeg()
# create a 6 pannel plot of the downloaded images
opar <- par(mfrow = c(2, 3), mar = c(1, 1, 2, 1))
for (i in 1:6) {
img <- jpeg::readJPEG(file.path(out_folder, azam_files$downloaded_file_name[i]))
plot(
1:2,
type = 'n',
axes = FALSE
)
graphics::rasterImage(img, 1, 1, 2, 2)
title(main = paste(
azam_files$country[i],
azam_files$date[i],
sep = "\n"
))
}
# reset par
par(opar)
# save to vignettes folder
grDevices::jpeg("amanitas.jpeg", width = 1200, height = 800, quality = 100)
# create a 6 pannel plot of the downloaded images
opar <- par(mfrow = c(2, 3), mar = c(1, 1, 2, 1))
for (i in 1:6) {
img <- jpeg::readJPEG(file.path(out_folder, azam_files$downloaded_file_name[i]))
plot(
1:2,
type = 'n',
axes = FALSE
)
graphics::rasterImage(img, 1, 1, 2, 2)
title(main = paste(
azam_files$country[i],
azam_files$date[i],
sep = "\n"
))
}
dev.off()
# save to vignettes folder
grDevices::jpeg("amanitas.jpeg", width = 1200, height = 800, quality = 200)
# save to vignettes folder
grDevices::jpeg("amanitas.jpeg", width = 1200, height = 800, res = 200)
# create a 6 pannel plot of the downloaded images
opar <- par(mfrow = c(2, 3), mar = c(1, 1, 2, 1))
for (i in 1:6) {
img <- jpeg::readJPEG(file.path(out_folder, azam_files$downloaded_file_name[i]))
plot(
1:2,
type = 'n',
axes = FALSE
)
graphics::rasterImage(img, 1, 1, 2, 2)
title(main = paste(
azam_files$country[i],
azam_files$date[i],
sep = "\n"
))
}
dev.off()
# reset par
par(opar)
# save to vignettes folder
grDevices::jpeg("amanitas.jpeg", width = 1200, height = 800, res = 150)
# create a 6 pannel plot of the downloaded images
opar <- par(mfrow = c(2, 3), mar = c(1, 1, 2, 1))
for (i in 1:6) {
img <- jpeg::readJPEG(file.path(out_folder, azam_files$downloaded_file_name[i]))
plot(
1:2,
type = 'n',
axes = FALSE
)
graphics::rasterImage(img, 1, 1, 2, 2)
title(main = paste(
azam_files$country[i],
azam_files$date[i],
sep = "\n"
))
}
dev.off()
# reset par
par(opar)
# save to vignettes folder
grDevices::jpeg("amanitas.jpeg", width = 600, height = 400, res = 100)
# create a 6 pannel plot of the downloaded images
opar <- par(mfrow = c(2, 3), mar = c(1, 1, 2, 1))
for (i in 1:6) {
img <- jpeg::readJPEG(file.path(out_folder, azam_files$downloaded_file_name[i]))
plot(
1:2,
type = 'n',
axes = FALSE
)
graphics::rasterImage(img, 1, 1, 2, 2)
title(main = paste(
azam_files$country[i],
azam_files$date[i],
sep = "\n"
))
}
dev.off()
# reset par
par(opar)
# save to vignettes folder
grDevices::jpeg("amanitas.jpeg", width = 600, height = 400, res = 120)
# create a 6 pannel plot of the downloaded images
opar <- par(mfrow = c(2, 3), mar = c(1, 1, 2, 1))
for (i in 1:6) {
img <- jpeg::readJPEG(file.path(out_folder, azam_files$downloaded_file_name[i]))
plot(
1:2,
type = 'n',
axes = FALSE
)
graphics::rasterImage(img, 1, 1, 2, 2)
title(main = paste(
azam_files$country[i],
azam_files$date[i],
sep = "\n"
))
}
dev.off()
# reset par
par(opar)
# query GBIF for longspined porcupinefish images
d_holocanthus <- query_gbif(species = "Diodon holocanthus", format = "image")
# keep only JPEG records (for simplicity for this vignette)
d_holocanthus <- d_holocanthus[d_holocanthus$file_extension == "jpeg", ]
# select 6 random JPEG records
set.seed(666)
d_holocanthus <- d_holocanthus[sample(seq_len(nrow(d_holocanthus)), 6),]
# create folder for images
out_folder <- file.path(tempdir(), "diodon_holocanthus")
dir.create(out_folder)
# download media files creating sub-directories by country
dhol_files <- download_media(metadata = d_holocanthus,
path = out_folder,
folder_by = "country")
# save to vignettes folder
grDevices::jpeg("porcupinefish.jpeg", width = 600, height = 400, res = 120)
# create a 6 pannel plot of the downloaded images
# create a 6 pannel plot of the downloaded images
opar <- par(mfrow = c(2, 3), mar = c(1, 1, 2, 1))
for (i in 1:6) {
img <- jpeg::readJPEG(file.path(out_folder, dhol_files$downloaded_file_name[i]))
plot(
1:2,
type = 'n',
axes = FALSE
)
graphics::rasterImage(img, 1, 1, 2, 2)
title(main = paste(
substr(dhol_files$country[i], start = 1, stop = 14),
dhol_files$date[i],
sep = "\n"
))
}
dev.off()
# reset par
par(opar)
covr::file_coverage(
source_files = "./R/query_macaulay.R",
test_files = "./tests/testthat/test_query_macaulay.R")
rlang::last_trace()
devtools::install()
# Execute the code from the vignette
knitr::knit("vignettes/suwo.Rmd.orig", output = "vignettes/suwo.Rmd")
devtools::install()
# Execute the code from the vignette
knitr::knit("vignettes/suwo.Rmd.orig", output = "vignettes/suwo.Rmd")
df1 <- try(
query_wikiaves(
species = 'Glaucis dohrnii',
format = "sound",
all_data = FALSE
),
silent = TRUE
)
expected_col_names <- suwo:::.format_query_output(only_basic_columns = T)
expected_col_names
query_col_names
query_col_names %in% expected_col_names
all(query_col_names %in% expected_col_names)
all(expected_col_names %in% query_col_names)
expected_col_names
query_col_names
df1
nrow(df1)
test_that("test all_data FALSE", {
skip_on_cran()
skip_if_offline()
df1 <- try(
query_wikiaves(
species = 'Glaucis dohrnii',
format = "sound",
all_data = FALSE
),
silent = TRUE
)
# skip_if(suwo:::.is_error(df1))
#
#   expected_col_names <- suwo:::.format_query_output(only_basic_columns = T)
#
#   query_col_names <- colnames(df1)
#
#   expect_true(
#     all(query_col_names %in% expected_col_names) &
#       all(expected_col_names %in% query_col_names),
#     info = "Column names do not match the expected names"
#   )
expect_equal(nrow(df1), 36)
})
library(testthat)
test_that("test all_data FALSE", {
skip_on_cran()
skip_if_offline()
df1 <- try(
query_wikiaves(
species = 'Glaucis dohrnii',
format = "sound",
all_data = FALSE
),
silent = TRUE
)
# skip_if(suwo:::.is_error(df1))
#
#   expected_col_names <- suwo:::.format_query_output(only_basic_columns = T)
#
#   query_col_names <- colnames(df1)
#
#   expect_true(
#     all(query_col_names %in% expected_col_names) &
#       all(expected_col_names %in% query_col_names),
#     info = "Column names do not match the expected names"
#   )
expect_equal(nrow(df1), 36)
})
#run document twice
if (!nzchar(Sys.getenv("xc_api_key")))
Sys.setenv(xc_api_key = getPass::getPass())
devtools::document(".")
devtools::check(document = TRUE, run_dont_test = TRUE, vignettes = TRUE, manual = TRUE)
devtools::document(".")
devtools::check(document = TRUE, run_dont_test = TRUE, vignettes = TRUE, manual = TRUE)
devtools::document(".")
devtools::check(document = TRUE, run_dont_test = TRUE, vignettes = TRUE, manual = TRUE)
load("~/Dropbox/R_package_testing/suwo/R/sysdata.rda")
devtools::document(".")
devtools::check(document = TRUE, run_dont_test = TRUE, vignettes = TRUE, manual = TRUE)
devtools::document(".")
devtools::check(document = TRUE, run_dont_test = TRUE, vignettes = TRUE, manual = TRUE)
