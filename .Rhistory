# add missing columns to all data frames in X
data$results <- lapply(data$results, function(e){
nms <- names(e)
if (length(nms) != length(common_names))
for (o in common_names[!common_names %in% nms]) {
e <-
data.frame(e,
NA,
stringsAsFactors = FALSE,
check.names = FALSE)
names(e)[ncol(e)] <- o
}
return(e)
})
# all results in a single data frame
output_df <- do.call(rbind, data$results)
output_df$page <- (i/100) + 1
return(output_df)
})
# get common names to all data frames in X
common_names <- unique(unlist(lapply(query_output_list, names)))
# add missing columns to all data frames in X
query_output_list<- lapply(query_output_list, function(e){
nms <- names(e)
if (length(nms) != length(common_names))
for (o in common_names[!common_names %in% nms]) {
e <-
data.frame(e,
NA,
stringsAsFactors = FALSE,
check.names = FALSE)
names(e)[ncol(e)] <- o
}
return(e)
})
# all results in a single data frame
query_output_df <- do.call(rbind, query_output_list)
#Change column name for media download function
colnames(query_output_df)[colnames(query_output_df) == "media_URL"] <- "file_url"
#Add repository ID
query_output_df$repository <- "Observation"
View(query_output_df)
source("~/Dropbox/R_package_testing/suwo/R/query_observation.R")
qo <- query_observation(term = "Phaethornis guy", type = "still image")
View(qo)
source("~/Dropbox/R_package_testing/suwo/R/query_observation.R")
qo <- query_observation(term = "Phaethornis guy", type = "still image")
source("~/Dropbox/R_package_testing/suwo/R/query_observation.R")
qo <- query_observation(term = "Phaethornis guy", type = "still image")
View(qo)
data
length(data$results)
#JSON format
data <- fromJSON(dataURL)
length(data$results)
# Make the GET request and retrieve the response
dataURL <- getURL(url_inquiry, httpheader = headers)
#JSON format
data <- fromJSON(dataURL)
data
data$results
data$results$permalink
data$results$sounds
data$results$photos
unlist(data$results$photos)
source("~/Documentos/GitHub/suwo/R/internal_functions.R", echo=TRUE)
source("~/Documentos/GitHub/suwo/R/query_observation.R", echo=TRUE)
query_observation("turdus grayi", type = "still image")
install.packages("RCrul")
install.packages("RCurl")
query_observation("turdus grayi", type = "still image")
library(RCurl)
install.packages(RCurl)
install.packages("RCurl")
token = "uRCV1wSMhMUrKgzpsN1V6IUnvJl0Vl"
devtools::load_all(".")
df1 <- query_observation(term = 'Glaucis aeneus', type = "still image", token = token, cores = 1)
i <- 200
u <- 37
term = 'Glaucis aeneus'
type = "still image"
cores = 1
type <-
"StillImage"
# If cores is not numeric
if (!is.numeric(cores))
stop2("'cores' must be a numeric vector of length 1")
if (any(!(cores %% 1 == 0), cores < 1))
stop2("'cores' should be a positive integer")
#format JSON
term <- gsub(" ", "%20", term)
srch_trm <- paste0("https://observation.org/api/v1/species/search/?", "q=", term)
base.srch.pth <- jsonlite::fromJSON(srch_trm)
# If species not found in repository
if (base.srch.pth$count==0)
stop2("Species was not found in database")
library(RCurl)
library(jsonlite)
# Set the species ID and API endpoint URL
species_id <- base.srch.pth$results$id
url_inquiry <- paste0("https://observation.org/api/v1/species/", species_id, "/observations/?limit=100")
# Set the authorization header with your bearer token
bearer_token <- token
headers <- c("Authorization" = paste("Bearer", bearer_token))
# Make the GET request and retrieve the response
dataURL <- getURL(url_inquiry, httpheader = headers)
#JSON format
data <- fromJSON(dataURL)
data_org <- data
# message number of results
if (pb & verbose)
cat(paste(colortext(paste0("Obtaining metadata (matching observation(s) found)"), "success"), add_emoji("happy"), ":\n"))
# get total number of pages
offsets <- (seq_len(ceiling(data$count / 100)) - 1) * 100
# set clusters for windows OS
if (Sys.info()[1] == "Windows" & cores > 1)
cl <- parallel::makePSOCKcluster(getOption("cl.cores", cores)) else cl <- cores
query_output_list <- pblapply_sw_int(offsets, cl = 1, pbar = pb, function(i)
{
print(i)
#
srch_trm <- paste0("https://observation.org/api/v1/species/", species_id, "/observations/?limit=100")
dataURL <- getURL(paste0(srch_trm, "&offset=", i), httpheader = headers)
#JSON format
data <- fromJSON(dataURL)
# format as list of data frame
data$results <- lapply(seq_len(nrow(data$results)), function(u) {
x <- data$results[u, ]
print(u)
if(type == "StillImage"){
media_URL <- if (length(x$photos[[1]]) > 0)
unlist(x$photos) else
NA
}
if(type == "Sound"){
media_URL <- if (length(x$sounds[[1]]) > 0)
unlist(x$sounds) else
NA
}
# remove lists
x <- x[!sapply(x, is.list)]
# make it data frame
# X_df <- data.frame(t(unlist(x)))
# add media details
X_df <- data.frame(x, media_URL, row.names = seq_len(length(media_URL)))
# remove NAs
X_df <- X_df[!is.na(X_df$media_URL), ]
X_df$species_name <- if (nrow(X_df) > 0) data_org$results$species_detail$scientific_name[u] else vector(mode= "character")
return(X_df)
})
# get common names to all data frames in X
common_names <- unique(unlist(lapply(data$results, names)))
# add missing columns to all data frames in X
data$results <- lapply(data$results, function(e){
nms <- names(e)
if (length(nms) != length(common_names))
for (o in common_names[!common_names %in% nms]) {
e <-
data.frame(e,
NA,
stringsAsFactors = FALSE,
check.names = FALSE)
names(e)[ncol(e)] <- o
}
return(e)
})
# all results in a single data frame
output_df <- do.call(rbind, data$results)
output_df$page <- if (nrow(output_df) > 1) i/100 else vector(length = 0L)
return(output_df)
})
# get common names to all data frames in X
common_names <- unique(unlist(lapply(query_output_list, names)))
# add missing columns to all data frames in X
query_output_list<- lapply(query_output_list, function(e){
nms <- names(e)
if (length(nms) != length(common_names))
for (o in common_names[!common_names %in% nms]) {
e <-
data.frame(e,
NA,
stringsAsFactors = FALSE,
check.names = FALSE)
names(e)[ncol(e)] <- o
}
return(e)
})
# all results in a single data frame
query_output_df <- do.call(rbind, query_output_list)
#Change column name for media download function
colnames(query_output_df)[colnames(query_output_df) == "media_URL"] <- "file_url"
colnames(query_output_df)[colnames(query_output_df) == "id"] <- "key"
colnames(query_output_df)[colnames(query_output_df) == "species"] <- "species_code"
colnames(query_output_df)[colnames(query_output_df) == "species_name"] <- "species"
#Add repository ID
query_output_df$repository <- "Observation"
query_output_df <- subset(query_output_df, select = -c(page))
source("~/Documentos/GitHub/suwo/R/query_observation.R")
df1 <- query_observation(term = 'Glaucis aeneus', type = "still image", token = token, cores = 1)
source("~/Documentos/GitHub/suwo/R/query_observation.R")
i
u
df1 <- query_observation(term = 'Glaucis aeneus', type = "still image", token = token, cores = 1)
term
i
offsets
print(i)
#
srch_trm <- paste0("https://observation.org/api/v1/species/", species_id, "/observations/?limit=100")
dataURL <- getURL(paste0(srch_trm, "&offset=", i), httpheader = headers)
#JSON format
data <- fromJSON(dataURL)
# format as list of data frame
data$results <- lapply(seq_len(nrow(data$results)), function(u) {
x <- data$results[u, ]
print(u)
if(type == "StillImage"){
media_URL <- if (length(x$photos[[1]]) > 0)
unlist(x$photos) else
NA
}
if(type == "Sound"){
media_URL <- if (length(x$sounds[[1]]) > 0)
unlist(x$sounds) else
NA
}
# remove lists
x <- x[!sapply(x, is.list)]
# make it data frame
# X_df <- data.frame(t(unlist(x)))
# add media details
X_df <- data.frame(x, media_URL, row.names = seq_len(length(media_URL)))
# remove NAs
X_df <- X_df[!is.na(X_df$media_URL), ]
X_df$species_name <- if (nrow(X_df) > 0) data_org$results$species_detail$scientific_name[u] else vector(mode= "character")
return(X_df)
})
source("~/Documentos/GitHub/suwo/R/query_observation.R")
source("~/Documentos/GitHub/suwo/R/query_observation.R")
df1 <- query_observation2(term = 'Glaucis aeneus', type = "still image", token = token, cores = 1)
df1
source("~/Documentos/GitHub/suwo/R/query_observation.R", echo=TRUE)
df1 <- query_observation(term = 'Glaucis aeneus', type = "still image", token = token, cores = 1)
token = "uRCV1wSMhMUrKgzpsN1V6IUnvJl0Vl"
df1 <- query_observation(term = 'Glaucis aeneus', type = "still image", token = token, cores = 1)
expect_true(nrow(df1) >= 237)
nrow(df1)
View(df1)
source("~/Documentos/GitHub/suwo/tests/testthat/test_query_observation.R", echo=TRUE)
library(testthat)
test_that("search Glaucis dohrnii still image", {
df1 <- query_observation(term = 'Glaucis dohrnii', type = "still image", token = token)
# system(paste("firefox", df1$link[1]))
expect_true(nrow(df1) >= 1)
})
test_that("search Glaucis dohrnii still image", {
df1 <- query_observation(term = 'Glaucis dohrnii', type = "still image", token = token)
# system(paste("firefox", df1$link[1]))
expect_true(nrow(df1) >= 1)
})
df1 <- query_observation(term = 'Glaucis dohrnii', type = "still image", token = token)
df1 <- query_observation(term = 'Glaucis aeneus', type = "still image", token = token, cores = 1)
df1 <- query_observation(term = 'Glaucis aeneus', type = "still image", token = token, cores = 1)
df1 <- query_observation(term = 'Glaucis dohrnii', type = "still image", token = token)
source("~/Documentos/GitHub/suwo/R/query_observation.R", echo=TRUE)
df1 <- query_observation2(term = 'Glaucis dohrnii', type = "still image", token = token)
source("~/Documentos/GitHub/suwo/R/query_observation.R", echo=TRUE)
df1 <- query_observation2(term = 'Glaucis dohrnii', type = "still image", token = token)
source("~/Documentos/GitHub/suwo/R/query_observation.R")
source("~/Documentos/GitHub/suwo/R/query_observation.R")
source("~/Documentos/GitHub/suwo/R/query_observation.R")
source("~/Documentos/GitHub/suwo/R/query_observation.R")
source("~/Documentos/GitHub/suwo/R/query_observation.R", echo=TRUE)
df1 <- query_observation2(term = 'Glaucis dohrnii', type = "still image", token = token)
df1 <- query_observation2(term = 'Glaucis dohrnii', type = "still image", token = token)
source("~/Documentos/GitHub/suwo/tests/testthat/test_query_observation.R", echo=TRUE)
a <- "aalychnis lemur"
type(a)
class(a)
source("~/Documentos/GitHub/suwo/R/query_gbif.R", echo=TRUE)
source("~/Documentos/GitHub/suwo/R/internal_functions.R", echo=TRUE)
query_gbif(term = "phaethornis guy", type = "still image")
a <- query_gbif(term = "phaethornis guy", type = "still image")
a
a <- query_gbif(term = 1, type = "still image")
download_media <- function(metadata, path = "./", pb= TRUE, verbose = TRUE, cores = 1){
# check arguments
arguments <- as.list(base::match.call())[-1]
# add objects to argument names
for(i in names(arguments))
arguments[[i]] <- get(i)
# check each arguments
check_results <- check_arguments(args = arguments)
# report errors
checkmate::reportAssertions(check_results)
# Add file extension
metadata$extension  <- vapply(X = metadata$file_url, FUN = function(x){
x2 <- strsplit(x, "\\?")[[1]][1]
max_x2 <- max(gregexpr("\\.", x2)[[1]])
extension <- substr(x = x2, start = max_x2, stop = nchar(x2))
if (extension == ".mpga")
extension <- ".mp3"
return(extension)
}, FUN.VALUE = character(1), USE.NAMES = FALSE)
#Abbreviate repository name
repo <- metadata$repository[1]
metadata$repository <- switch(repo,
XC = "XC",
Observation = "OBS",
GBIF = "GBIF",
wikiaves = "WA",
INAT = "INAT",
Macaulay = "ML")
# rename if any duplicated names
metadata$non_dup_key <- unlist(lapply(
unique(metadata$key),
function(x) {
on <- metadata$key[metadata$key == x]
if (length(on) > 1) {
return(paste0(on, "-", seq_len(length(on))))
} else {
return(x)
}
}
))
# create file name
metadata$file.name <- paste0(gsub(pattern = " ", "_", x = metadata$species), "-", metadata$repository, metadata$non_dup_key, metadata$extension)
# set clusters for windows OS
if (pb  & verbose)
write(file = "", x = "Downloading files...")
if (Sys.info()[1] == "Windows" & cores > 1)
cl <- parallel::makePSOCKcluster(getOption("cl.cores", cores)) else cl <- cores
success_dwnld <- unlist(pblapply_sw_int(pbar = pb, X = 1:nrow(metadata), cl = cl, FUN = function(x)
{
downloadFUN(metadata, x)
}))
#   if (pb & verbose) write(file = "", x ="double-checking downloaded files")
#
#   #check if some files have no data
#   fl <- list.files(path = path, pattern = ".mp3$")
#   size0 <- fl[file.size(file.path(path, fl)) == 0]
#
#   #if so redo those files
#   if (length(size0) > 0)
#   {  Y <- metadata[metadata$file.name %in% size0, ]
#   unlink(size0)
#
#   # set clusters for windows OS
#   if (Sys.info()[1] == "Windows" & cores > 1)
#     cl <- parallel::makePSOCKcluster(getOption("cl.cores", cores)) else cl <- cores
#
#
#   a1 <- pblapply_sw_int(pbar = pb, X = 1:nrow(Y), cl = cl, FUN = function(x)
#   {
#     try(downloadFUN(Y, x), silent = TRUE)
#   })
# }
if (any(!success_dwnld)){
.Options$suwo$failed_downloads  <- c(metadata$file.name[!success_dwnld])
message("Some files couldn't be downloaded, check `.Options$suwo$failed_downloads`")
}
}
source("~/Documentos/GitHub/suwo/R/internal_functions.R", echo=TRUE)
source("~/Documentos/GitHub/suwo/R/download_media.R", echo=TRUE)
source("~/Documentos/GitHub/suwo/R/query_xenocanto.R", echo=TRUE)
df1 <- query_xenocanto(term = 'Phaethornis anthophilus')[1:2, ]
df1
download_media(metadata = df1, path = tempdir())
source("~/Documentos/GitHub/suwo/R/download_media.R", echo=TRUE)
download_media(metadata = df1, path = tempdir())
source("~/Documentos/GitHub/suwo/R/download_media.R", echo=TRUE)
download_media(metadata = df1, path = tempdir())
source("~/Documentos/GitHub/suwo/R/download_media.R", echo=TRUE)
source("~/Documentos/GitHub/suwo/R/download_media.R", echo=TRUE)
download_media(metadata = df1, path = tempdir())
warbleR::open_wd(path=tempdir())
source("~/Documentos/GitHub/suwo/R/internal_functions.R", echo=TRUE)
source("~/Documentos/GitHub/suwo/R/download_media.R", echo=TRUE)
download_media(metadata = df1, path = tempdir())
df1 <- query_wikiaves(term = 'Glaucis dohrnii', type = "sound")[1:2, ]
source("~/Documentos/GitHub/suwo/tests/testthat/test_query_wikiaves.R", echo=TRUE)
source("~/Documentos/GitHub/suwo/R/query_wikiaves.R", echo=TRUE)
df1 <- query_wikiaves(term = 'Glaucis dohrnii', type = "sound")[1:2, ]
download_media(metadata = df1, path = tempdir())
#run document twice
devtools::document(".")
rm(list = c("download_media", "query_wikiaves", "query_xenocanto"))
#run document twice
devtools::document(".")
#check with devtools
devtools::check(".", document = FALSE, run_dont_test = FALSE, vignettes = FALSE, manual = FALSE, )
df1 <- query_gbif(term = 'Glaucis dohrnii', type =  "sound")
df1
#install.packages("httr")
#install.packages("readr")
library(httr)
library(readr)
update_dataset_object <- function(gbif_datasets) {
# Download the CSV file
response <- GET(url)
# Check if the download was successful
if (http_type(response) == "text/csv") {
# Read the CSV data
csv_data <- read_csv(text = content(response, "text"))
# Update the dataset object with the new data
gbif_datasets <- csv_data
# Return the updated object
return(gbif_datasets)
} else {
stop("Failed to download CSV.")
}
}
update_dataset_object <- function(gbif_datasets) {
# Download the CSV file
response <- GET("https://api.gbif.org/v1/dataset/search/export?format=CSV&")
# Check if the download was successful
if (http_type(response) == "text/csv") {
# Read the CSV data
csv_data <- read_csv(text = content(response, "text"))
# Update the dataset object with the new data
gbif_datasets <- csv_data
# Return the updated object
return(gbif_datasets)
} else {
stop("Failed to download CSV.")
}
}
source("~/Documentos/GitHub/suwo/tests/testthat/gbif_dataset_update.R", echo=TRUE)
update_gbif_datasets()
# Download the CSV file
response <- GET("https://api.gbif.org/v1/dataset/search/export?format=CSV&")
#run document twice
devtools::document(".")
#check with devtools
devtools::check(".", document = FALSE, run_dont_test = FALSE, vignettes = FALSE, manual = FALSE, )
#run document twice
devtools::document(".")
#check with devtools
devtools::check(".", document = FALSE, run_dont_test = FALSE, vignettes = FALSE, manual = FALSE, )
df1 <- query_xenocanto(term = 'Phaethornis anthophilus')[1:2, ]
df1
download_media(metadata = df1, path = tempdir())
df1 <- query_wikiaves(term = 'Glaucis dohrnii', type = "sound")[1:2, ]
download_media(metadata = df1, path = tempdir())
df1 <- query_gbif(term = 'Glaucis dohrnii', type = "sound")[1:2, ]
download_media(metadata = df1, path = tempdir())
df1 <- query_xenocanto(term = 'Phaethornis anthophilus')[1:2, ]
df1 <- query_wikiaves(term = 'Glaucis dohrnii', type = "sound")[1:2, ]
metadata <- df1
# check arguments
arguments <- as.list(base::match.call())[-1]
# Add file extension
metadata$extension  <- vapply(X = metadata$file_url, FUN = function(x){
x2 <- strsplit(x, "\\?")[[1]][1]
max_x2 <- max(gregexpr("\\.", x2)[[1]])
extension <- substr(x = x2, start = max_x2, stop = nchar(x2))
if (extension == ".mpga")
extension <- ".mp3"
return(extension)
}, FUN.VALUE = character(1), USE.NAMES = FALSE)
metadata
#Abbreviate repository name
repo <- metadata$repository[1]
metadata$repository <- switch(repo,
XC = "XC",
Observation = "OBS",
GBIF = "GBIF",
wikiaves = "WA",
INAT = "INAT",
Macaulay = "ML")
metadata
# rename if any duplicated names
metadata$non_dup_key <- unlist(lapply(
unique(metadata$key),
function(x) {
on <- metadata$key[metadata$key == x]
if (length(on) > 1) {
return(paste0(on, "-", seq_len(length(on))))
} else {
return(x)
}
}
))
metadata
# create file name
metadata$file.name <- paste0(gsub(pattern = " ", "_", x = metadata$species), "-", metadata$repository, metadata$non_dup_key, metadata$extension)
metadata
#run document twice
devtools::document(".")
#check with devtools
devtools::check(".", document = FALSE, run_dont_test = FALSE, vignettes = FALSE, manual = FALSE, )
download_media(metadata = df1, path = tempdir())
df1 <- query_wikiaves(term = 'Glaucis dohrnii', type = "sound")[1:2, ]
download_media(metadata = df1, path = tempdir())
#run document twice
devtools::document(".")
#run document twice
devtools::document(".")
rm(list = c("update_gbif_datasets"))
#run document twice
devtools::document(".")
query_gbif(term = "glaucis dohrnii", type = "sound")
# check internet connection
a <- try(RCurl::getURL("https://api.gbif.org/v1/occurrence/search?"), silent = TRUE)
if (is(a, "try-error")) {
stop2("No connection to GBIF API (check your internet connection!)")
}
if (a == "Could not connect to the database") {
stop2("GBIF website is apparently down")
}
a <- try(RCurl::getURL("https://api.gbif.org/v1/"), silent = TRUE)
a
