unlink(tempdir(), recursive = TRUE, force = TRUE)
download_media(metadata = df1, path = tempdir())
fls <- list.files(path = tempdir(), ignore.case = TRUE, full.names = TRUE)
expect_equal(fls, c("Agalychnis_lemur-INAT149945235",
"Agalychnis_lemur-INAT170947000"))
})
test_that("search inaturalist sp download", {
df1 <- query_inaturalist(term = 'Agalychnis lemur', type = "still image")
test_keys <- c("149945235", "170947000")
df1 <- subset(df1, key %in% test_keys)
# remove files
unlink(tempdir(), force = TRUE)
download_media(metadata = df1, path = tempdir())
fls <- list.files(path = tempdir(), ignore.case = TRUE, full.names = TRUE)
expect_equal(fls, c("Agalychnis_lemur-INAT149945235",
"Agalychnis_lemur-INAT170947000"))
})
test_that("search inaturalist sp download", {
df1 <- query_inaturalist(term = 'Agalychnis lemur', type = "still image")
test_keys <- c("149945235", "170947000")
df1 <- subset(df1, key %in% test_keys)
download_media(metadata = df1, path = tempdir())
fls <- list.files(path = tempdir(), ignore.case = TRUE, full.names = TRUE)
# remove files
unlink(tempdir(), recursive = TRUE, force = TRUE)
expect_equal(fls, c("Agalychnis_lemur-INAT149945235",
"Agalychnis_lemur-INAT170947000"))
})
tempdir()
warbleR::open_wd(path = tempdir())
tempdir()
warbleR::open_wd(path = tempdir())
test_that("search inaturalist sp download", {
df1 <- query_inaturalist(term = 'Agalychnis lemur', type = "still image")
test_keys <- c("149945235", "170947000")
df1 <- subset(df1, key %in% test_keys)
download_media(metadata = df1, path = tempdir())
fls <- list.files(path = tempdir(), pattern = "\\.jpeg$", ignore.case = TRUE, full.names = TRUE)
# remove files
unlink(file.path(tempdir(), fls))
expect_equal(fls, c("Agalychnis_lemur-INAT149945235",
"Agalychnis_lemur-INAT170947000"))
})
library(testthat)
#run document twice
devtools::document(".")
test_that("search inaturalist sp download", {
df1 <- query_inaturalist(term = 'Agalychnis lemur', type = "still image")
test_keys <- c("149945235", "170947000")
df1 <- subset(df1, key %in% test_keys)
download_media(metadata = df1, path = tempdir())
fls <- list.files(path = tempdir(), pattern = "\\.jpeg$", ignore.case = TRUE, full.names = TRUE)
# remove files
unlink(file.path(tempdir(), fls))
expect_equal(fls, c("Agalychnis_lemur-INAT149945235",
"Agalychnis_lemur-INAT170947000"))
})
warbleR::open_wd(path = tempdir())
#run document twice
devtools::document(".")
#run document twice
devtools::document(".")
test_that("search inaturalist sp download", {
df1 <- query_inaturalist(term = 'Agalychnis lemur', type = "still image")
test_keys <- c("149945235", "170947000")
df1 <- subset(df1, key %in% test_keys)
download_media(metadata = df1, path = tempdir())
fls <- list.files(path = tempdir(), pattern = "\\.jpeg$", ignore.case = TRUE, full.names = TRUE)
# remove files
unlink(file.path(tempdir(), fls))
expect_equal(fls, c("Agalychnis_lemur-INAT149945235",
"Agalychnis_lemur-INAT170947000"))
})
warbleR::open_wd(path = tempdir())
warbleR::open_wd(path = tempdir())
test_that("search inaturalist sp download", {
df1 <- query_inaturalist(term = 'Agalychnis lemur', type = "still image")
test_keys <- c("149945235", "170947000")
df1 <- subset(df1, key %in% test_keys)
download_media(metadata = df1, path = tempdir())
fls <- list.files(path = tempdir(), pattern = "\\.jpeg$", ignore.case = TRUE, full.names = TRUE)
# remove files
unlink(file.path(tempdir(), fls))
expect_equal(fls, c("Agalychnis_lemur-INAT149945235",
"Agalychnis_lemur-INAT170947000"))
})
#run document twice
devtools::document(".")
test_that("search inaturalist sp download", {
df1 <- query_inaturalist(term = 'Agalychnis lemur', type = "still image")
test_keys <- c("149945235", "170947000")
df1 <- subset(df1, key %in% test_keys)
download_media(metadata = df1, path = tempdir())
fls <- list.files(path = tempdir(), pattern = "\\.jpeg$", ignore.case = TRUE, full.names = TRUE)
# remove files
unlink(file.path(tempdir(), fls))
expect_equal(fls, c("Agalychnis_lemur-INAT149945235",
"Agalychnis_lemur-INAT170947000"))
})
test_that("search inaturalist sp download", {
df1 <- query_inaturalist(term = 'Agalychnis lemur', type = "still image")
test_keys <- c("149945235", "170947000")
df1 <- subset(df1, key %in% test_keys)
download_media(metadata = df1, path = tempdir())
fls <- list.files(path = tempdir(), pattern = ".jpeg$", ignore.case = TRUE, full.names = TRUE)
# remove files
unlink(file.path(tempdir(), fls))
expect_equal(fls, c("Agalychnis_lemur-INAT149945235",
"Agalychnis_lemur-INAT170947000"))
})
test_that("search inaturalist sp download", {
df1 <- query_inaturalist(term = 'Agalychnis lemur', type = "still image")
test_keys <- c("149945235", "170947000")
df1 <- subset(df1, key %in% test_keys)
download_media(metadata = df1, path = tempdir())
fls <- list.files(path = tempdir(), pattern = ".jpeg$", ignore.case = TRUE)
# remove files
unlink(file.path(tempdir(), fls))
expect_equal(fls, c("Agalychnis_lemur-INAT149945235",
"Agalychnis_lemur-INAT170947000"))
})
test_that("search inaturalist sp download", {
df1 <- query_inaturalist(term = 'Agalychnis lemur', type = "still image")
test_keys <- c("149945235", "170947000")
df1 <- subset(df1, key %in% test_keys)
download_media(metadata = df1, path = tempdir())
fls <- list.files(path = tempdir(), pattern = ".jpeg$", ignore.case = TRUE)
# remove files
unlink(file.path(tempdir(), fls))
expect_equal(fls, c("Agalychnis_lemur-INAT149945235.jpeg",
"Agalychnis_lemur-INAT170947000.jpeg"))
})
warbleR::open_wd(path = tempdir())
metadata <- query_inaturalist(term = "Agalychnis lemur", type = "still image")
if (metadata$repository[1] == "INAT"){
if (!exists("media_extension", where = metadata)) {
metadata$extension <- vapply(X = metadata$file_url, FUN = function(x) {
x2 <- strsplit(x, "\\?")[[1]][1]
max_x2 <- max(gregexpr("\\.", x2)[[1]])
extension <- ".jpeg"
return(extension)
}, FUN.VALUE = character(1), USE.NAMES = FALSE)
}
}
metadata$extension
# rename if any duplicated names
metadata$non_dup_key <- unlist(lapply(
unique(metadata$key),
function(x) {
on <- metadata$key[metadata$key == x]
if (length(on) > 1) {
return(paste0(on, "-", seq_len(length(on))))
} else {
return(x)
}
}
))
metadata$non_dup_key
# create file name
metadata$file.name <- paste0(gsub(pattern = " ", "_", x = metadata$species), "-", metadata$repository, metadata$non_dup_key, metadata$extension)
metadata$file.name
# Function to download file according to repository
downloadFUN <- function(metadata, x) {
dl_result <- try(download.file(
url = as.character(metadata$file_url[x]),
destfile = file.path(path, metadata$file.name[x]),
quiet = TRUE, mode = "wb", cacheOK = TRUE,
extra = getOption("download.file.extra")
), silent = TRUE)
if (is(dl_result, "try-error")) {
return(FALSE)
} else {
return(TRUE)
}
}
path = tempdir()
# Function to download file according to repository
downloadFUN <- function(metadata, x) {
dl_result <- try(download.file(
url = as.character(metadata$file_url[x]),
destfile = file.path(path, metadata$file.name[x]),
quiet = TRUE, mode = "wb", cacheOK = TRUE,
extra = getOption("download.file.extra")
), silent = TRUE)
if (is(dl_result, "try-error")) {
return(FALSE)
} else {
return(TRUE)
}
}
warbleR::open_wd(path = tempdir())
dl_result <- try(download.file(
url = as.character(metadata$file_url[x]),
destfile = file.path(path, metadata$file.name[x]),
quiet = TRUE, mode = "wb", cacheOK = TRUE,
extra = getOption("download.file.extra")
), silent = TRUE)
dl_result <- try(download.file(
url = as.character(metadata$file_url[x]),
destfile = file.path(path, metadata$file.name[x]),
quiet = TRUE, mode = "wb", cacheOK = TRUE,
extra = getOption("download.file.extra")
), silent = TRUE)
#run document twice
devtools::document(".")
download_media(metadata)
download_media(metadata, path= tempdir())
test_that("Xenocanto Phaethornis anthophilus download", {
df1 <- query_xenocanto(term = 'Phaethornis anthophilus')
test_keys <- c("532163", "568491")
df1 <- subset(df1, key %in% test_keys)
download_media(metadata = df1, path = tempdir())
fls <- list.files(path = tempdir(), pattern = "mp3$")
# remove files
unlink(file.path(tempdir(), fls))
expect_equal(fls, c("Phaethornis_anthophilus-XC532163.mp3", "Phaethornis_anthophilus-XC568491.mp3"))
})
df1 <- query_xenocanto(term = 'Phaethornis anthophilus')
test_keys <- c("532163", "568491")
df1 <- subset(df1, key %in% test_keys)
download_media(metadata = df1, path = tempdir())
test_that("wikiaves Glaucis dohrnii sp download", {
df1 <- query_wikiaves(term = 'Glaucis dohrnii', type = "sound")
test_keys <- c("2286824", "4522545")
df1 <- subset(df1, key %in% test_keys)
download_media(metadata = df1, path = tempdir())
fls <- list.files(path = tempdir(), pattern = "mp3$")
# remove files
unlink(file.path(tempdir(), fls))
expect_equal(fls, c("Glaucis_dohrnii-WA2286824.mp3",
"Glaucis_dohrnii-WA4522545.mp3"))
})
test_that("search GBIF sp download", {
df1 <- query_gbif(term = 'Glaucis dohrnii', type = "sound")
test_keys <- c("3863342525", "3863345521")
df1 <- subset(df1, key %in% test_keys)
download_media(metadata = df1, path = tempdir())
fls <- list.files(path = tempdir(), pattern = "mp3$")
# remove files
unlink(file.path(tempdir(), fls))
expect_equal(fls, c("Glaucis_dohrnii-GBIF3863342525.mp3",
"Glaucis_dohrnii-GBIF3863345521.mp3"))
})
test_that("search inaturalist sp download", {
df1 <- query_inaturalist(term = 'Agalychnis lemur', type = "still image")
test_keys <- c("149945235", "170947000")
df1 <- subset(df1, key %in% test_keys)
download_media(metadata = df1, path = tempdir())
fls <- list.files(path = tempdir(), pattern = ".jpeg$", ignore.case = TRUE)
# remove files
unlink(file.path(tempdir(), fls))
expect_equal(fls, c("Agalychnis_lemur-INAT149945235.jpeg",
"Agalychnis_lemur-INAT170947000.jpeg"))
})
#run document twice
devtools::document(".")
test_that("search GBIF sp download", {
df1 <- query_gbif(term = 'Glaucis dohrnii', type = "sound")
test_keys <- c("3863342525", "3863345521")
df1 <- subset(df1, key %in% test_keys)
download_media(metadata = df1, path = tempdir())
fls <- list.files(path = tempdir(), pattern = "mp3$")
# remove files
unlink(file.path(tempdir(), fls))
expect_equal(fls, c("Glaucis_dohrnii-GBIF3863342525.mp3",
"Glaucis_dohrnii-GBIF3863345521.mp3"))
})
library(testthat)
test_that("search GBIF sp download", {
df1 <- query_gbif(term = 'Glaucis dohrnii', type = "sound")
test_keys <- c("3863342525", "3863345521")
df1 <- subset(df1, key %in% test_keys)
download_media(metadata = df1, path = tempdir())
fls <- list.files(path = tempdir(), pattern = "mp3$")
# remove files
unlink(file.path(tempdir(), fls))
expect_equal(fls, c("Glaucis_dohrnii-GBIF3863342525.mp3",
"Glaucis_dohrnii-GBIF3863345521.mp3"))
})
test_that("wikiaves Glaucis dohrnii sp download", {
df1 <- query_wikiaves(term = 'Glaucis dohrnii', type = "sound")
test_keys <- c("2286824", "4522545")
df1 <- subset(df1, key %in% test_keys)
download_media(metadata = df1, path = tempdir())
fls <- list.files(path = tempdir(), pattern = "mp3$")
# remove files
unlink(file.path(tempdir(), fls))
expect_equal(fls, c("Glaucis_dohrnii-WA2286824.mp3",
"Glaucis_dohrnii-WA4522545.mp3"))
})
#run document twice
devtools::document(".")
check_gbif_datasets()
warbleR::open_wd(path = tempdir())
msg <- capture.output(a <- check_gbif_datasets())
msg
#run document twice
devtools::document(".")
query_inaturalist(term = "Buchwaldoboletus xylophilus", type = "still image")
res <- query_inaturalist(term = "Buchwaldoboletus xylophilus", type = "still image")
View(res)
res <- query_gbif(term = "Buchwaldoboletus xylophilus", type = "still image")
res <- query_gbif(term = "Buchwaldoboletus xylophilus", type = "still image", dataset = "50c9509d-22c7-4a22-a47d-8c48425ef4a7")
#run document twice
devtools::document(".")
res <- query_gbif(term = "Buchwaldoboletus xylophilus", type = "still image", dataset = "50c9509d-22c7-4a22-a47d-8c48425ef4a7")
dataset = "50c9509d-22c7-4a22-a47d-8c48425ef4a7"
#' # search without downloading
# df1 <- query_gbif(term = 'Turdus iliacus', type = "Sound", cores = 4)
#' View(df1)
#' }
#'
#' @references {
#'
#' }
#' @author Marcelo Araya-Salas (\email{marcelo.araya@@ucr.ac.cr})
#'
query_gbif <-
function(term = NULL,
type = c("sound", "still image", "moving image", "interactive resource"),
cores = 1,
pb = TRUE,
verbose = TRUE,
dataset = NULL,
all_data = TRUE) {
# check arguments
arguments <- as.list(base::match.call())[-1]
# add objects to argument names
for (i in names(arguments)) {
arguments[[i]] <- get(i)
}
# check each arguments
check_results <- check_arguments(args = arguments)
# report errors
checkmate::reportAssertions(check_results)
# type must be supplied
if (is.null(type)) {
stop2("'type' must be supplied")
}
org_type <- match.arg(type)
type <- switch(type,
sound = "Sound",
`still image` = "StillImage",
`moving image` = "MovingImage",
`interactive resource` = "InteractiveResource"
)
# term must be supplied
if (is.null(term)) {
stop2("'term' must be supplied")
}
if (tolower(Sys.info()[["sysname"]]) != "windows"){
# check internet connection
a <- try(RCurl::getURL("https://api.gbif.org/"), silent = TRUE)
if (is(a, "try-error")) {
stop2("No connection to GBIF API (check your internet connection!)")
}
if (a == "Could not connect to the database") {
stop2("GBIF website is apparently down")
}
}
# If cores is not numeric
if (!is.numeric(cores)) {
stop2("'cores' must be a numeric vector of length 1")
}
if (any(!(cores %% 1 == 0), cores < 1)) {
stop2("'cores' should be a positive integer")
}
# fix term for html
term <- gsub(" ", "%20", term)
srch_trm <- paste0(
"https://api.gbif.org/v1/occurrence/search?limit=300&",
if (is.null(dataset)) "" else dataset,
"scientificName=", term, "&media_type=",
type
)
base.srch.pth <- jsonlite::fromJSON(srch_trm)
# message if nothing found
if (base.srch.pth$count == 0) {
if (verbose) {
cat(paste(colortext(paste0("No ", tolower(org_type), "s were found"), "failure"), add_emoji("sad")))
}
} else {
# message number of results
if (pb & verbose) {
cat(paste(colortext(paste0("Obtaining metadata (", base.srch.pth$count, " matching observation(s) found)"), "success"), add_emoji("happy"), ":\n"))
}
# get total number of pages
offsets <- (seq_len(ceiling(base.srch.pth$count / base.srch.pth$limit)) - 1) * 300
# set clusters for windows OS
if (Sys.info()[1] == "Windows" & cores > 1) {
cl <- parallel::makePSOCKcluster(getOption("cl.cores", cores))
} else {
cl <- cores
}
query_output_list <- pblapply_sw_int(offsets, cl = 1, pbar = pb, function(i) {
query_output <- jsonlite::fromJSON(paste0(srch_trm, "&offset=", i))
# format as list of data frame
query_output$results <- lapply(seq_len(nrow(query_output$results)), function(u) {
x <- query_output$results[u, ]
# media_df <- do.call(rbind, media_list)
media_df <- do.call(rbind, x$media)
# select type
media_df <- media_df[media_df$type == type, ]
# fix identifier column name
names(media_df)[names(media_df) == "identifier"] <- "URL"
names(media_df) <- paste0("media-", names(media_df))
# remove lists
x <- x[!sapply(x, is.list)]
# make it data frame
X_df <- data.frame(t(unlist(x)))
# add media details
X_df <- cbind(X_df, media_df)
return(X_df)
})
# get common names to all data frames in X
common_names <- unique(unlist(lapply(query_output$results, names)))
# add missing columns to all data frames in X
query_output$results <- lapply(query_output$results, function(e) {
nms <- names(e)
if (length(nms) != length(common_names)) {
for (o in common_names[!common_names %in% nms]) {
e <-
data.frame(e,
NA,
stringsAsFactors = FALSE,
check.names = FALSE
)
names(e)[ncol(e)] <- o
}
}
return(e)
})
# all results in a single data frame
output_df <- do.call(rbind, query_output$results)
output_df$page <- i
return(output_df)
})
# get common names to all data frames in X
common_names <- unique(unlist(lapply(query_output_list, names)))
# add missing columns to all data frames in X
query_output_list <- lapply(query_output_list, function(e) {
nms <- names(e)
if (length(nms) != length(common_names)) {
for (o in common_names[!common_names %in% nms]) {
e <-
data.frame(e,
NA,
stringsAsFactors = FALSE,
check.names = FALSE
)
names(e)[ncol(e)] <- o
}
}
return(e)
})
# all results in a single data frame
query_output_df <- do.call(rbind, query_output_list)
# Change column name for media download function
names(query_output_df)[names(query_output_df) == "media-URL"] <- "file_url"
# Add repository ID
query_output_df$repository <- "GBIF"
if (!all_data) {
names(query_output_df)[names(query_output_df) == "decimalLatitude"] <- "latitude"
names(query_output_df)[names(query_output_df) == "decimalLongitude"] <- "longitude"
names(query_output_df)[names(query_output_df) == "scientificName"] <- "species"
names(query_output_df)[names(query_output_df) == "key"] <- "key"
names(query_output_df)[names(query_output_df) == "eventDate"] <- "date"
names(query_output_df)[names(query_output_df) == "locality"] <- "location"
query_output_df <- query_output_df[, c("key", "species", "date", "country", "location", "latitude", "longitude", "file_url", "repository")]
}
return(query_output_df)
}
}
term = "Buchwaldoboletus xylophilus"
type = "still image"
org_type <- match.arg(type)
type <- switch(type,
sound = "Sound",
`still image` = "StillImage",
`moving image` = "MovingImage",
`interactive resource` = "InteractiveResource"
)
# fix term for html
term <- gsub(" ", "%20", term)
srch_trm <- paste0(
"https://api.gbif.org/v1/occurrence/search?limit=300&",
if (is.null(dataset)) "" else dataset,
"scientificName=", term, "&media_type=",
type
)
srch_trm
srch_trm <- paste0(
"https://api.gbif.org/v1/occurrence/search?limit=300&",
if (is.null(dataset)) "" else "scientificName=", dataset,
"scientificName=", term, "&media_type=",
type
)
srch_trm
srch_trm <- paste0(
"https://api.gbif.org/v1/occurrence/search?limit=300&",
if (is.null(dataset)) "" else "dataset=", dataset,
"scientificName=", term, "&media_type=",
type
)
srch_trm
#run document twice
devtools::document(".")
rm(list = c("query_gbif"))
#run document twice
devtools::document(".")
res <- query_gbif(term = "Buchwaldoboletus xylophilus", type = "still image", dataset = "50c9509d-22c7-4a22-a47d-8c48425ef4a7")
res
