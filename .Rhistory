names(tur_ruf_sound_list) <- gsub("_sounds", "", names(tur_ruf_sound_list))
Repository <- sapply(tur_ruf_sound_list, function(x) x[1, "repository"])
Function <- sapply(tur_ruf_sound_list, function(x) attributes(x)$query_call[[1]])
Function <- sapply(Function, as.character)
file_types <- sapply(Function, function(x) paste(formals(x)$format, collapse = ", "))
file_types <- gsub("c, ", "", file_types)
file_types[Function == "query_xenocanto"] <- "sound"
urls = c(
gbif = "https://www.gbif.org/",
inaturalist = "https://www.inaturalist.org/",
macaulay = "https://www.macaulaylibrary.org/",
observation = "https://observation.org/",
wikiaves = "https://www.wikiaves.com.br/",
`xeno-canto` = "https://www.xeno-canto.org/"
)
urls <- urls[match(names(tur_ruf_sound_list), names(urls))]
token <- c(
gbif = "No",
inaturalist = "No",
macaulay = "No",
observation = "Yes",
wikiaves = "No",
`xeno-canto` = "Yes"
)
token <- token[match(names(tur_ruf_sound_list), names(token))]
tax_level <-  c(
gbif = "Species",
inaturalist = "Species",
macaulay = "Species",
observation = "Species",
wikiaves = "Species",
`xeno-canto` = "Species, genus, family"
)
tax_level <- tax_level[match(names(tur_ruf_sound_list), names(tax_level))]
geo_cover <-  c(
gbif = "Worldwide",
inaturalist = "Worldwide",
macaulay = "Worldwide",
observation = "Worldwide",
wikiaves = "Brazil",
`xeno-canto` = "Worldwide"
)
geo_cover <- geo_cover[match(names(tur_ruf_sound_list), names(geo_cover))]
colnames <- lapply(tur_ruf_sound_list, names)
colnames <- lapply(colnames, function(x) setdiff(x, suwo:::.format_query_output(only_basic_columns = TRUE)))
additional_data <- sapply(colnames, function(x) paste(x, collapse = ", "))
additional_data <- additional_data[match(names(tur_ruf_sound_list), names(additional_data))]
query_summary <- data.frame(
Function = Function,
Repository = Repository,
`URL link` = urls,
`File types` = file_types,
`Requires token` = token,
`Taxonomic level` = tax_level,
`Geographic coverage` = geo_cover,
`Additional data` = additional_data,
stringsAsFactors = FALSE,
check.names = FALSE
)
query_summary$`URL link` <- kableExtra::cell_spec(query_summary$`URL link`, "html", link = query_summary$`URL link`, new_tab = TRUE)
query_summary$Function <- kableExtra::cell_spec(query_summary$Function, "html", link = paste0("https://marce10.github.io/suwo/reference/", query_summary$Function, ".html"), new_tab = TRUE)
query_summary[, names(query_summary) != "Additional data"] |>
kableExtra::kbl(
caption = "Table 1: Summary of query functions.",
format = "html",
escape = FALSE,
row.names = FALSE
) |>
kableExtra::kable_styling(
bootstrap_options = c("striped", "hover", "condensed", "responsive"),
full_width = FALSE,
position = "left"
)
# Chunk 5
# Load suwo package
library(suwo)
# Query Xeno-canto for Turdus rufiventris sounds
truf_xc <- query_xenocanto(term = "Turdus rufiventris")
head(truf_xc, 4)
# Chunk 7
head(tur_ruf_sound_list$wikiaves[, suwo:::.format_query_output(only_basic_columns = TRUE)], 4)
# Chunk 8
query_summary[,c("Function", "Additional data")] |>
kableExtra::kbl(
caption = "Table 2: Additional metadata per query function.",
format = "html",
escape = FALSE,
row.names = FALSE
) |>
kableExtra::kable_styling(
bootstrap_options = c("striped", "hover", "condensed", "responsive"),
full_width = FALSE,
position = "left"
)
# Chunk 9
# exclude new observations (simulate old data)
old_truf_xc <- subset_metadata(truf_xc, date <= "2024-12-31" | is.na(date))
# update "old" data
updated_xc <- update_metadata(metadata = old_truf_xc)
# compare number of records
nrow(truf_xc) == nrow(updated_xc)
# Chunk 11
# find duplicates
dups_merged_metadata <- find_duplicates(merged_metadata)
# look first 6 columns
head(dups_merged_metadata)
# query GBIF for Amanita zambiana images
amus_gbf <- query_gbif(term = "Amanita zambiana", format = "image")
# download media files to a temporary directory
amus_files <- download_media(metadata = amus_gbf, path = tempdir())
amus_files
for (i in 1:6) {
img <- jpeg::readJPEG(amus_files$download_file_path[i])
plot(1:2, type = 'n', xlab = '', ylab = '', axes = FALSE)
rasterImage(img, 1, 1, 2, 2)
title(main = paste(amus_files$species[i], "\n", amus_files$date[i]), line = -1)
}
amus_files$download_file_path[i]
for (i in 1:6) {
img <- jpeg::readJPEG(file.path(tempdir(amus_files$download_file_name[i])))
plot(1:2, type = 'n', xlab = '', ylab = '', axes = FALSE)
rasterImage(img, 1, 1, 2, 2)
title(main = paste(amus_files$species[i], "\n", amus_files$date[i]), line = -1)
}
file.path(tempdir(amus_files$download_file_name[i]))
file.path(tempdir(amus_files$download_file_name[i]))
for (i in 1:6) {
img <- jpeg::readJPEG(file.path(tempdir(), amus_files$download_file_name[i])))
# create a 6 pannel plot of the downloaded images
par(mfrow = c(2, 3), mar = c(1, 1, 2, 1))
for (i in 1:6) {
img <- jpeg::readJPEG(file.path(tempdir(), amus_files$download_file_name[i]))
plot(1:2, type = 'n', xlab = '', ylab = '', axes = FALSE)
rasterImage(img, 1, 1, 2, 2)
title(main = paste(amus_files$species[i], "\n", amus_files$date[i]), line = -1)
}
title(main = paste(amus_files$species[i], amus_files$country[i], amus_files$date[i]), line = -1)
# create a 6 pannel plot of the downloaded images
par(mfrow = c(2, 3), mar = c(1, 1, 2, 1))
for (i in 1:6) {
img <- jpeg::readJPEG(file.path(tempdir(), amus_files$download_file_name[i]))
plot(1:2, type = 'n', xlab = '', ylab = '', axes = FALSE)
rasterImage(img, 1, 1, 2, 2)
title(main = paste(amus_files$species[i], amus_files$country[i], amus_files$date[i]), line = -1)
}
# create a 6 pannel plot of the downloaded images
par(mfrow = c(2, 3), mar = c(1, 1, 2, 1))
for (i in 1:6) {
img <- jpeg::readJPEG(file.path(tempdir(), amus_files$download_file_name[i]))
plot(1:2, type = 'n', xlab = '', ylab = '', axes = FALSE)
rasterImage(img, 1, 1, 2, 2)
title(main = paste(amus_files$species[i], amus_files$country[i], amus_files$date[i]), sep = "/",  line = 1)
}
# create a 6 pannel plot of the downloaded images
par(mfrow = c(2, 3), mar = c(1, 1, 2, 1))
for (i in 1:6) {
img <- jpeg::readJPEG(file.path(tempdir(), amus_files$download_file_name[i]))
plot(1:2, type = 'n', xlab = '', ylab = '', axes = FALSE)
rasterImage(img, 1, 1, 2, 2)
title(main = paste(amus_files$species[i], amus_files$country[i], amus_files$date[i], sep = "/"), line = 1)
}
# create a 6 pannel plot of the downloaded images
par(mfrow = c(2, 3), mar = c(1, 1, 2, 1))
for (i in 1:6) {
img <- jpeg::readJPEG(file.path(tempdir(), amus_files$download_file_name[i]))
plot(1:2, type = 'n', xlab = '', ylab = '', axes = FALSE)
rasterImage(img, 1, 1, 2, 2)
title(main = paste(amus_files$species[i], amus_files$country[i], amus_files$date[i], sep = "/ "))
}
# create a 6 pannel plot of the downloaded images
par(mfrow = c(2, 3), mar = c(1, 1, 2, 1))
for (i in 1:6) {
img <- jpeg::readJPEG(file.path(tempdir(), amus_files$download_file_name[i]))
plot(1:2, type = 'n', xlab = '', ylab = '', axes = FALSE)
rasterImage(img, 1, 1, 2, 2)
title(main = paste(amus_files$species[i], amus_files$country[i], amus_files$date[i], sep = " / "))
}
View(dups_merged_metadata)
table(dups_merged_metadata$duplicate_group)
# look at duplicated group 39
subset(dups_merged_metadata, duplicate_group == 39)
amus_files2 <- download_media(metadata = amus_gbf, path = tempdir(), folder_by = "country")
amus_files2
amus_gbf <- subset_metadata(amus_gbf, 1:6)
amus_gbf
attributes(amus_gbf)
amus_files2
source("~/Dropbox/R_package_testing/suwo/R/download_media.R")
# download media files to a temporary directory, creating sub-directories by country
amus_files2 <- download_media(metadata = amus_gbf, path = tempdir(), folder_by = "country")
file.path(NULL, "asd", "12213")
file.path("asd", "12213")
source("~/Dropbox/R_package_testing/suwo/R/download_media.R")
# download media files to a temporary directory, creating sub-directories by country
amus_files2 <- download_media(metadata = amus_gbf, path = tempdir(), folder_by = "country")
source("~/Dropbox/R_package_testing/suwo/R/download_media.R")
# download media files to a temporary directory, creating sub-directories by country
amus_files2 <- download_media(metadata = amus_gbf, path = tempdir(), folder_by = "country")
amus_files2
# create a 6 pannel plot of the downloaded images
par(mfrow = c(2, 3), mar = c(1, 1, 2, 1))
for (i in 1:6) {
img <- jpeg::readJPEG(file.path(tempdir(), amus_files$download_file_name[i]))
plot(
1:2,
type = 'n',
xlab = '',
ylab = '',
axes = FALSE
)
rasterImage(img, 1, 1, 2, 2)
title(main = paste(
amus_files$country[i],
amus_files$date[i],
sep = " \n "
))
}
# create a 6 pannel plot of the downloaded images
par(mfrow = c(2, 3), mar = c(1, 1, 2, 1))
for (i in 1:6) {
img <- jpeg::readJPEG(file.path(tempdir(), amus_files$download_file_name[i]))
plot(
1:2,
type = 'n',
axes = FALSE
)
rasterImage(img, 1, 1, 2, 2)
title(main = paste(
amus_files$country[i],
amus_files$date[i],
sep = " \n "
))
}
dev.off()
# create a 6 pannel plot of the downloaded images
par(mfrow = c(2, 3), mar = c(1, 1, 2, 1))
for (i in 1:6) {
img <- jpeg::readJPEG(file.path(tempdir(), amus_files$download_file_name[i]))
plot(
1:2,
type = 'n',
axes = FALSE
)
rasterImage(img, 1, 1, 2, 2)
title(main = paste(
amus_files$country[i],
amus_files$date[i],
sep = " \n "
))
}
devtools::install()
devtools::check(document = TRUE, run_dont_test = TRUE, vignettes = FALSE, manual = TRUE)
devtools::check(document = TRUE, run_dont_test = TRUE, vignettes = FALSE, manual = TRUE)
run.all()
options(verbose = TRUE)
devtools::test()
beepr::beep(2)
xc1 <- query_xenocanto(term = 'Phaethornis anthophilus', all_data = FALSE)
test_keys <- c("532163", "568491")
sxc1 <- subset(xc1, key %in% test_keys)
a <- download_media(metadata = sxc1, path = tempdir(), folder_by = "date")
fls <- list.files(path = tempdir(), pattern = "mp3$", recursive = TRUE)
fls
a
a <- download_media(metadata = sxc1, path = tempdir(), folder_by = "date")
fls <- list.files(path = tempdir(), pattern = "mp3$", recursive = TRUE)
fls
list.files(path = tempdir(), pattern = "mp3$", recursive = TRUE)
warbleR::open_wd(tempdir())
source("~/Dropbox/R_package_testing/suwo/R/download_media.R")
a <- download_media(metadata = sxc1, path = tempdir(), folder_by = "date")
fls <- list.files(path = tempdir(), pattern = "mp3$", recursive = TRUE)
fls
# remove filess
unlink(file.path(tempdir(), fls))
expected_files <- c("2020-03-05/Phaethornis_anthophilus-XC532163.mp3", "2020-06-14/Phaethornis_anthophilus-XC568491.mp3")
all(expected_files %in% fls)
all(a$download_file_name %in% basename(expected_files))
a$download_file_name
all(a$download_file_name %in% expected_files)
run.all()
options(verbose = TRUE)
devtools::test()
beepr::beep(2)
ml1 <- query_macaulay(term = 'Glaucis dohrnii', format = "sound", all_data = TRUE, path = tempdir())
sml1 <- subset(ml1, key %in% test_keys)
a <- download_media(metadata = sml1, path = tempdir())
sml1
ml1
ml1$key
sml1 <- subset(ml1, key %in% test_keys)
sml1
ml1
key %in% test_keys
sml1$key %in% test_keys
ml1$key %in% test_keys
ml1$key
test_keys <- c(627919111, 624733750)
ml1$key %in% test_keys
test_keys <- c(627919111, 624733750)
sml1 <- subset(ml1, key %in% test_keys)
a <- download_media(metadata = sml1, path = tempdir())
fls <- list.files(path = tempdir(), pattern = ".mp3$|m4a$", ignore.case = TRUE)
# remove files
unlink(file.path(tempdir(), fls))
expected_files <- c("Glaucis_dohrnii-ML627919111.mp3", "Glaucis_dohrnii-ML624733750.mp3")
all(expected_files %in% fls)
all(a$download_file_name %in% fls)
devtools::install()
load("~/Dropbox/R_package_testing/suwo/R/sysdata.rda")
wa <- query_wikiaves(term = 'Glaucis dohrnii', format =  "sound")
xc <- query_xenocanto(term = 'Glaucis dohrnii')
# combine metadata
merged_metadata <- merge_metadata(wa, xc)
# find duplicates
label_dup_metadata <- find_duplicates(metadata = merged_metadata)
label_dup_metadata
label_dup_metadata$duplicate_group
gb <- query_gbif(term = 'Glaucis dohrnii', format =  "sound")
merged_metadata <- merge_metadata(wa, gb)
label_dup_metadata <- find_duplicates(metadata = merged_metadata)
label_dup_metadata
label_dup_metadata$duplicate_group
gb <- query_gbif(term = "Turdus rufiventris", format =  "sound")
xc <- query_xenocanto(term = "Turdus rufiventris")
merged_metadata <- merge_metadata(xc, gb)
label_dup_metadata <- find_duplicates(metadata = merged_metadata)
label_dup_metadata
label_dup_metadata
metadata <- label_dup_metadata
# get data with no duplicates
no_dups <- metadata[is.na(metadata$duplicate_group), ]
# get data with duplicates
dups <- metadata[!is.na(metadata$duplicate_group), ]
x =  1
sub_dups <- dups[dups$duplicate_group == x, ]
sub_dups
# count possible duplicates by repository
repo_counts <- table(sub_dups$repository)
repo_counts
# get repo with more observations
top_repo <- names(repo_counts)[which.max(repo_counts)]
top_repo
order(sub_dups$repository, decreasing = TRUE)
sub_dups$repository
sort("Macaulay", "Xeno-Canto", "GBIF")
sort(c("Macaulay", "Xeno-Canto", "GBIF"))
sort(c("Macaulay", "Xeno-Canto", "GBIF"), decreasing = T)
table(metadata$repository)
table(suwo:::merged_metadata$repository)
# order so XC and GBIF are on top if available and then the rest in this order
priority_repos <- c("Xeno-Canto", "GBIF", "iNaturalist", "Macaulay Library", "Wikiaves", "Observation")
priority_repos
# order according to priority
sub_dups$repository <- factor(sub_dups$repository, levels = priority_repos)
sub_dups$repository
order(sub_dups$repository)
# subset of duplicates
sub_dups <- dups[dups$duplicate_group == x, ]
# order so XC and GBIF are on top if available and then the rest in this order
priority_repos <- c("Xeno-Canto", "GBIF", "iNaturalist", "Macaulay Library", "Wikiaves", "Observation")
# order according to priority
sub_dups$repository_factor <- factor(sub_dups$repository, levels = priority_repos)
sub_dups$repository_factor
sub_dups <- sub_dups[order(as.numeric(sub_dups$repository)), ]
sub_dups
sub_dups <- sub_dups[order(as.numeric(sub_dups$repository_factor)), ]
sub_dups
# count possible duplicates by repository
repo_counts <- table(sub_dups$repository)
# get repo with more observations
if (same_repo){
# if same_repo is TRUE, keep only one observation per repository
sub_dups <- sub_dups[!duplicated(sub_dups$repository), ]
} else {
if (length(unique(repo_counts)) == 1){
# select XC if available, if not GBIF if not, any
if ("Xeno-Canto" %in% names(repo_counts)){
top_repo <- "Xeno-Canto"
} else if ("GBIF" %in% names(repo_counts)){
top_repo <- "GBIF"
} else {
top_repo <- names(repo_counts)[1]
}
} else {
top_repo <- names(repo_counts)[which.max(repo_counts)]
}
sub_dups <- sub_dups[sub_dups$repository == top_repo, ]
}
# select which repo to use
which.min(priority_repos %in% names(repo_counts))
priority_repos
names(repo_counts)
priority_repos %in% names(repo_counts)
# select which repo to use
which(priority_repos %in% names(repo_counts))
# select which repo to use
which.min(which(priority_repos %in% names(repo_counts)))
source("~/Dropbox/R_package_testing/suwo/R/remove_duplicates.R")
source("~/Dropbox/R_package_testing/suwo/R/remove_duplicates.R")
dedup_metadata <- remove_duplicates(label_dup_metadata)
source("~/Dropbox/R_package_testing/suwo/R/remove_duplicates.R")
dedup_metadata <- remove_duplicates(label_dup_metadata)
View(dedup_metadata)
source("~/Dropbox/R_package_testing/suwo/R/remove_duplicates.R")
dedup_metadata <- remove_duplicates(label_dup_metadata)
dedup_metadata
nrow(dedup_metadata)
nrow(label_dup_metadata)
dedup_metadata <- remove_duplicates(label_dup_metadata, same_repo = TRUE)
nrow(dedup_metadata)
source("~/Dropbox/R_package_testing/suwo/R/remove_duplicates.R")
dedup_metadata <- remove_duplicates(label_dup_metadata, same_repo = TRUE)
nrow(dedup_metadata)
dedup_metadata <- remove_duplicates(label_dup_metadata, same_repo = F)
nrow(dedup_metadata)
wa <- query_wikiaves(term = 'Glaucis dohrnii', format =  "sound")
xc <- query_xenocanto(term = 'Glaucis dohrnii')
merged_mt <- merge_metadata(wa, xc)
# get metadata from 2 repos
gb <- query_gbif(term = "Turdus rufiventris", format =  "sound")
xc <- query_xenocanto(term = "Turdus rufiventris")
# combine metadata
merged_metadata <- merge_metadata(xc, gb)
# find duplicates
label_dup_metadata <- find_duplicates(metadata = merged_metadata)
# remove duplicates
dedup_metadata <- remove_duplicates(label_dup_metadata)
nrow(dedup_metadata)
# find duplicates
label_dup_metadata <- find_duplicates(metadata = suwo:::merged_metadata)
# remove duplicates
dedup_metadata <- remove_duplicates(label_dup_metadata)
nrow(dedup_metadata)
nrow(  suwo:::merged_metadata
)
# remove duplicates
dedup_metadata2 <- remove_duplicates(label_dup_metadata, same_repo = FALSE)
dedup_metadata2
nrow(dedup_metadata2)
# remove duplicates
dedup_metadata2 <- remove_duplicates(label_dup_metadata, same_repo = TRUE)
nrow(dedup_metadata2)
label_dup_metadata
label_dup_metadata <- find_duplicates(metadata = suwo:::merged_metadata)
tab <- table(label_dup_metadata$duplicate_group)
tab
tab <- unique(label_dup_metadata$duplicate_group)
grps <- unique(label_dup_metadata$duplicate_group)
grps
length(grps)
sum(is.na(label_dup_metadata$duplicate_group))
devtools::check(document = TRUE, run_dont_test = TRUE, vignettes = FALSE, manual = TRUE)
devtools::check(document = TRUE, run_dont_test = TRUE, vignettes = FALSE, manual = TRUE)
devtools::check(document = TRUE, run_dont_test = TRUE, vignettes = FALSE, manual = TRUE)
run.all()
options(verbose = TRUE)
devtools::test()
devtools::install()
# test a query with more than 10000 results paging by date
cal_cos <- query_macaulay(
term = "Calypte costae",
type = "image",
path = tempdir(),
dates = c(1976, 2020, 2022, 2024, 2025, 2026)
)
cal_cos <- query_macaulay(
term = "Calypte costae",
format = "image",
path = tempdir(),
dates = c(1976, 2020, 2022, 2024, 2025, 2026)
)
cal_cos <- query_macaulay(
term = "Calypte costae",
format = "image",
path = tempdir(),
dates = c(1976, 2020)
)
# get example macaulay data for calypte coste to show spliting by range
cal_cos <- query_macaulay(
term = "Calypte costae",
format = "image",
path = tempdir(),
dates = c(1976, 2018)
)
# get example macaulay data for calypte coste to show spliting by range
cal_cos <- query_macaulay(
term = "Calypte costae",
format = "image",
path = tempdir(),
dates = c(1976, 2019)
)
# get example macaulay data for calypte coste to show spliting by range
cal_cos <- query_macaulay(
term = "Calypte costae",
format = "image",
path = tempdir(),
dates = c(1976, 2019)
)
# get example macaulay data for calypte coste to show spliting by range
cal_cos <- query_macaulay(
term = "Calypte costae",
format = "image",
path = tempdir(),
dates = c(1976, 2019)
)
cal_cos <- query_macaulay(term = "Calypte costae", format = "image",
path = tempdir(), dates = c(1976, 2019, 2022, 2024, 2025, 2026))
source("~/.active-rstudio-document", echo=TRUE)
truf_ml <- query_macaulay(term = "Turdus rufiventris", format = "sound")
devtools::check(document = TRUE, run_dont_test = TRUE, vignettes = FALSE, manual = TRUE)
devtools::check(document = TRUE, run_dont_test = TRUE, vignettes = FALSE, manual = TRUE)
