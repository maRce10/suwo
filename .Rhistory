#' }
#'
#' @references {
#' Schubert, Stephanie Caroline, Lilian Tonelli Manica, and André De Camargo Guaraldo. 2019. Revealing the potential of a huge citizen-science platform to study bird migration. Emu-Austral Ornithology 119.4: 364-373.
#' }
#' @author Marcelo Araya-Salas (\email{marcelo.araya@@ucr.ac.cr})
#'
query_gbif <-
function(term = NULL,
type = NULL,
cores = 1,
pb = TRUE,
verbose = TRUE) {
# type must be supplied
if (is.null(type))
stop("'type' must be supplied")
# type must be supplied
if (is.null(term))
stop("'term' must be supplied")
#check internet connection
a <- try(RCurl::getURL("https://api.gbif.org/v1/occurrence/search?"), silent = TRUE)
if (is(a, "try-error"))
stop("No connection to GBIF API (check your internet connection!)")
if (a == "Could not connect to the database")
stop("GBIF website is apparently down")
# If cores is not numeric
if (!is.numeric(cores))
stop("'cores' must be a numeric vector of length 1")
if (any(!(cores %% 1 == 0), cores < 1))
stop("'cores' should be a positive integer")
# fix term for html
term <- gsub(" ", "%20", term)
base.srch.pth <- rjson::fromJSON(file = paste0("https://api.gbif.org/v1/occurrence/search?limit=300&species=", term))
# get total number of pages
num_pages <- ceiling(base.srch.pth$count / base.srch.pth$limit)
num_pages_id <- as.data.frame(seq_len(num_pages))
query_output_list <- pblapply_sw_int(seq_len(num_pages), cl = 1, pbar = pb, function(i)
{
query_output <-
as.array(jsonlite::fromJSON(
paste0(
"https://api.gbif.org/v1/occurrence/search?limit=300&","species=",term,"&media_type=",
if (type == "Sound")
"Sound" else if (type == "InteractiveResource")
"InteractiveResource" else if (type == "StillImage")
"StillImage" else
"MovingImage"
,"&offset="
,num_pages_id$`seq_len(num_pages)`[i]
)
)
)
# format as list of data frame
query_output$results <- lapply(query_output$results , function(x) {
media_list <- lapply(lapply(X$media, function(y) data.frame(t(unlist(y)))), function(w) data.frame(t(unlist(w))))
media_df <- do.call(rbind, media_list)
## fitler by media type
# media_df <- media_df[grep()]
# fix identifier column name
names(media_df)[names(media_df) == "identifier"] <- "URL"
# remove lists
x <- x[!sapply(x, is.list)]
# make it data frame
X_df <- data.frame(t(unlist(x)))
# add media details
X_df <- cbind(X_df, media_df)
return(X_df)
})
# all results in a single data frame
results <- do.call(rbind, query_output$results)
# get common names to all data frames in X
cnms <- unique(unlist(lapply(query_output$results, names)))
# add missing columns to all data frames in X
query_output$results <- lapply(query_output$results, function(e){
nms <- names(e)
if (length(nms) != length(cnms))
for (i in cnms[!cnms %in% nms]) {
e <-
data.frame(e,
NA,
stringsAsFactors = FALSE,
check.names = FALSE)
names(e)[ncol(e)] <- i
}
return(e)
})
return(output_df)
})
query_output_df <- do.call(rbind, query_output_list)
}
query_gbif("Turdus merula", "Sound")
#initialize search
query_output <- as.array(rjson::fromJSON(file = paste0(base.srch.pth)))
base.srch.pth <- rjson::fromJSON(file = paste0("https://api.gbif.org/v1/occurrence/search?media_type=Sound&limit=300&species=", term))
term="Turdus merula"
base.srch.pth <- rjson::fromJSON(file = paste0("https://api.gbif.org/v1/occurrence/search?media_type=Sound&limit=300&species=", term))
# fix term for html
term <- gsub(" ", "%20", term)
base.srch.pth <- rjson::fromJSON(file = paste0("https://api.gbif.org/v1/occurrence/search?media_type=Sound&limit=300&species=", term))
# get total number of pages
num_pages <- ceiling(base.srch.pth$count / base.srch.pth$limit)
num_pages
# format as list of data frame
query_output$results <- lapply(query_output$results , function(x) {
media_list <- lapply(lapply(x$media, function(y) data.frame(t(unlist(y)))), function(w) data.frame(t(unlist(w))))
media_df <- do.call(rbind, media_list)
## fitler by media type
# media_df <- media_df[grep()]
# fix identifier column name
names(media_df)[names(media_df) == "identifier"] <- "URL"
# remove lists
x <- x[!sapply(x, is.list)]
# make it data frame
X_df <- data.frame(t(unlist(x)))
# add media details
X_df <- cbind(X_df, media_df)
return(X_df)
})
query_output$results
# get common names to all data frames in X
cnms <- unique(unlist(lapply(query_output$results, names)))
# add missing columns to all data frames in X
query_output$results <- lapply(query_output$results, function(e){
nms <- names(e)
if (length(nms) != length(cnms))
for (i in cnms[!cnms %in% nms]) {
e <-
data.frame(e,
NA,
stringsAsFactors = FALSE,
check.names = FALSE)
names(e)[ncol(e)] <- i
}
return(e)
})
# all results in a single data frame
results <- do.call(rbind, query_output$results)
results
#' df1 <- query_gbif(term = 'Phaethornis anthophilus', download = FALSE)
#' View(df1)
#'
#' }
#'
#' @references {
#' Schubert, Stephanie Caroline, Lilian Tonelli Manica, and André De Camargo Guaraldo. 2019. Revealing the potential of a huge citizen-science platform to study bird migration. Emu-Austral Ornithology 119.4: 364-373.
#' }
#' @author Marcelo Araya-Salas (\email{marcelo.araya@@ucr.ac.cr})
#'
query_gbif <-
function(term = NULL,
type = NULL,
cores = 1,
pb = TRUE,
verbose = TRUE) {
# type must be supplied
if (is.null(type))
stop("'type' must be supplied")
# type must be supplied
if (is.null(term))
stop("'term' must be supplied")
#check internet connection
a <- try(RCurl::getURL("https://api.gbif.org/v1/occurrence/search?"), silent = TRUE)
if (is(a, "try-error"))
stop("No connection to GBIF API (check your internet connection!)")
if (a == "Could not connect to the database")
stop("GBIF website is apparently down")
# If cores is not numeric
if (!is.numeric(cores))
stop("'cores' must be a numeric vector of length 1")
if (any(!(cores %% 1 == 0), cores < 1))
stop("'cores' should be a positive integer")
# fix term for html
term <- gsub(" ", "%20", term)
base.srch.pth <- rjson::fromJSON(file = paste0("https://api.gbif.org/v1/occurrence/search?media_type=Sound&limit=300&species=", term))
# get total number of pages
num_pages <- ceiling(base.srch.pth$count / base.srch.pth$limit)
num_pages_id <- as.data.frame(seq_len(num_pages))
query_output_list <- pblapply_sw_int(seq_len(num_pages), cl = 1, pbar = pb, function(i)
{
query_output <-
jsonlite::fromJSON(
paste0(
"https://api.gbif.org/v1/occurrence/search?limit=300&","species=",term,"&media_type=",
if (type == "Sound")
"Sound" else if (type == "InteractiveResource")
"InteractiveResource" else if (type == "StillImage")
"StillImage" else
"MovingImage"
,"&offset="
,num_pages_id$`seq_len(num_pages)`[i]
)
)
# format as list of data frame
query_output$results <- lapply(query_output$results , function(x) {
media_list <- lapply(lapply(x$media, function(y) data.frame(t(unlist(y)))), function(w) data.frame(t(unlist(w))))
media_df <- do.call(rbind, media_list)
## fitler by media type
# media_df <- media_df[grep()]
# fix identifier column name
names(media_df)[names(media_df) == "identifier"] <- "URL"
# remove lists
x <- x[!sapply(x, is.list)]
# make it data frame
X_df <- data.frame(t(unlist(x)))
# add media details
X_df <- cbind(X_df, media_df)
return(X_df)
})
# get common names to all data frames in X
cnms <- unique(unlist(lapply(query_output$results, names)))
# add missing columns to all data frames in X
query_output$results <- lapply(query_output$results, function(e){
nms <- names(e)
if (length(nms) != length(cnms))
for (o in cnms[!cnms %in% nms]) {
e <-
data.frame(e,
NA,
stringsAsFactors = FALSE,
check.names = FALSE)
names(e)[ncol(e)] <- o
}
return(e)
})
# all results in a single data frame
results <- do.call(rbind, query_output$results)
return(output_df)
})
}
query_gbif("Turdus merula", "Sound")
seq_len(num_pages)
#' df1 <- query_gbif(term = 'Phaethornis anthophilus', download = FALSE)
#' View(df1)
#'
#' }
#'
#' @references {
#' Schubert, Stephanie Caroline, Lilian Tonelli Manica, and André De Camargo Guaraldo. 2019. Revealing the potential of a huge citizen-science platform to study bird migration. Emu-Austral Ornithology 119.4: 364-373.
#' }
#' @author Marcelo Araya-Salas (\email{marcelo.araya@@ucr.ac.cr})
#'
query_gbif <-
function(term = NULL,
type = NULL,
cores = 1,
pb = TRUE,
verbose = TRUE) {
# type must be supplied
if (is.null(type))
stop("'type' must be supplied")
# type must be supplied
if (is.null(term))
stop("'term' must be supplied")
#check internet connection
a <- try(RCurl::getURL("https://api.gbif.org/v1/occurrence/search?"), silent = TRUE)
if (is(a, "try-error"))
stop("No connection to GBIF API (check your internet connection!)")
if (a == "Could not connect to the database")
stop("GBIF website is apparently down")
# If cores is not numeric
if (!is.numeric(cores))
stop("'cores' must be a numeric vector of length 1")
if (any(!(cores %% 1 == 0), cores < 1))
stop("'cores' should be a positive integer")
# fix term for html
term <- gsub(" ", "%20", term)
base.srch.pth <- rjson::fromJSON(file = paste0("https://api.gbif.org/v1/occurrence/search?media_type=Sound&limit=300&species=", term))
# get total number of pages
num_pages <- ceiling(base.srch.pth$count / base.srch.pth$limit)
# num_pages_id <- as.data.frame(seq_len(num_pages))
query_output_list <- pblapply_sw_int(seq_len(num_pages), cl = 1, pbar = pb, function(i)
{
query_output <-
jsonlite::fromJSON(
paste0(
"https://api.gbif.org/v1/occurrence/search?limit=300&","species=",term,"&media_type=",
if (type == "Sound")
"Sound" else if (type == "InteractiveResource")
"InteractiveResource" else if (type == "StillImage")
"StillImage" else
"MovingImage"
,"&offset="
, i
)
)
# format as list of data frame
query_output$results <- lapply(query_output$results , function(x) {
media_list <- lapply(lapply(x$media, function(y) data.frame(t(unlist(y)))), function(w) data.frame(t(unlist(w))))
media_df <- do.call(rbind, media_list)
## fitler by media type
# media_df <- media_df[grep()]
# fix identifier column name
names(media_df)[names(media_df) == "identifier"] <- "URL"
# remove lists
x <- x[!sapply(x, is.list)]
# make it data frame
X_df <- data.frame(t(unlist(x)))
# add media details
X_df <- cbind(X_df, media_df)
return(X_df)
})
# get common names to all data frames in X
cnms <- unique(unlist(lapply(query_output$results, names)))
# add missing columns to all data frames in X
query_output$results <- lapply(query_output$results, function(e){
nms <- names(e)
if (length(nms) != length(cnms))
for (o in cnms[!cnms %in% nms]) {
e <-
data.frame(e,
NA,
stringsAsFactors = FALSE,
check.names = FALSE)
names(e)[ncol(e)] <- o
}
return(e)
})
# all results in a single data frame
results <- do.call(rbind, query_output$results)
return(output_df)
})
}
query_gbif("Turdus merula", "Sound")
source("~/Documentos/GitHub/suwo/R/query_gbif.R")
query_gbif("Turdus merula", "Sound")
term = "Turdus merula"
type = "Sound"
# fix term for html
term <- gsub(" ", "%20", term)
base.srch.pth <- rjson::fromJSON(file = paste0("https://api.gbif.org/v1/occurrence/search?media_type=Sound&limit=300&species=", term))
# get total number of pages
num_pages <- ceiling(base.srch.pth$count / base.srch.pth$limit)
num_pages
query_output_list <- pblapply_sw_int(seq_len(num_pages), cl = 1, pbar = pb, function(i)
{
print(i)
query_output <-
jsonlite::fromJSON(
paste0(
"https://api.gbif.org/v1/occurrence/search?limit=300&","species=",term,"&media_type=",
if (type == "Sound")
"Sound" else if (type == "InteractiveResource")
"InteractiveResource" else if (type == "StillImage")
"StillImage" else
"MovingImage"
,"&offset="
, i
)
)
# format as list of data frame
query_output$results <- lapply(query_output$results , function(x) {
media_list <- lapply(lapply(x$media, function(y) data.frame(t(unlist(y)))), function(w) data.frame(t(unlist(w))))
media_df <- do.call(rbind, media_list)
## fitler by media type
# media_df <- media_df[grep()]
# fix identifier column name
names(media_df)[names(media_df) == "identifier"] <- "URL"
# remove lists
x <- x[!sapply(x, is.list)]
# make it data frame
X_df <- data.frame(t(unlist(x)))
# add media details
X_df <- cbind(X_df, media_df)
return(X_df)
})
# get common names to all data frames in X
cnms <- unique(unlist(lapply(query_output$results, names)))
# add missing columns to all data frames in X
query_output$results <- lapply(query_output$results, function(e){
nms <- names(e)
if (length(nms) != length(cnms))
for (o in cnms[!cnms %in% nms]) {
e <-
data.frame(e,
NA,
stringsAsFactors = FALSE,
check.names = FALSE)
names(e)[ncol(e)] <- o
}
return(e)
})
# all results in a single data frame
results <- do.call(rbind, query_output$results)
return(output_df)
})
pb = TRUE
# type must be supplied
if (is.null(type))
stop("'type' must be supplied")
# type must be supplied
if (is.null(term))
stop("'term' must be supplied")
#check internet connection
a <- try(RCurl::getURL("https://api.gbif.org/v1/occurrence/search?"), silent = TRUE)
if (is(a, "try-error"))
stop("No connection to GBIF API (check your internet connection!)")
if (a == "Could not connect to the database")
stop("GBIF website is apparently down")
# If cores is not numeric
if (!is.numeric(cores))
stop("'cores' must be a numeric vector of length 1")
if (any(!(cores %% 1 == 0), cores < 1))
stop("'cores' should be a positive integer")
# fix term for html
term <- gsub(" ", "%20", term)
base.srch.pth <- rjson::fromJSON(file = paste0("https://api.gbif.org/v1/occurrence/search?media_type=Sound&limit=300&species=", term))
# get total number of pages
num_pages <- ceiling(base.srch.pth$count / base.srch.pth$limit)
query_output_list <- pblapply_sw_int(seq_len(num_pages), cl = 1, pbar = pb, function(i)
{
print(i)
query_output <-
jsonlite::fromJSON(
paste0(
"https://api.gbif.org/v1/occurrence/search?limit=300&","species=",term,"&media_type=",
if (type == "Sound")
"Sound" else if (type == "InteractiveResource")
"InteractiveResource" else if (type == "StillImage")
"StillImage" else
"MovingImage"
,"&offset="
, i
)
)
# format as list of data frame
query_output$results <- lapply(query_output$results , function(x) {
media_list <- lapply(lapply(x$media, function(y) data.frame(t(unlist(y)))), function(w) data.frame(t(unlist(w))))
media_df <- do.call(rbind, media_list)
## fitler by media type
# media_df <- media_df[grep()]
# fix identifier column name
names(media_df)[names(media_df) == "identifier"] <- "URL"
# remove lists
x <- x[!sapply(x, is.list)]
# make it data frame
X_df <- data.frame(t(unlist(x)))
# add media details
X_df <- cbind(X_df, media_df)
return(X_df)
})
# get common names to all data frames in X
cnms <- unique(unlist(lapply(query_output$results, names)))
# add missing columns to all data frames in X
query_output$results <- lapply(query_output$results, function(e){
nms <- names(e)
if (length(nms) != length(cnms))
for (o in cnms[!cnms %in% nms]) {
e <-
data.frame(e,
NA,
stringsAsFactors = FALSE,
check.names = FALSE)
names(e)[ncol(e)] <- o
}
return(e)
})
# all results in a single data frame
results <- do.call(rbind, query_output$results)
return(output_df)
})
query_output <-
jsonlite::fromJSON(
paste0(
"https://api.gbif.org/v1/occurrence/search?limit=300&","species=",term,"&media_type=",
if (type == "Sound")
"Sound" else if (type == "InteractiveResource")
"InteractiveResource" else if (type == "StillImage")
"StillImage" else
"MovingImage"
,"&offset="
, i
)
)
query_output
srch_trm <-  paste0(
"https://api.gbif.org/v1/occurrence/search?limit=300&","species=",term,"&media_type=",
if (type == "Sound")
"Sound" else if (type == "InteractiveResource")
"InteractiveResource" else if (type == "StillImage")
"StillImage" else
"MovingImage"
)
base.srch.pth <- rjson::fromJSON(file = srch_trm)
query_output <-
jsonlite::fromJSON(paste0(base.srch.pth, "&offset=", i)
)
paste0(base.srch.pth, "&offset=", i)
paste0(base.srch.pth, "&offset=", i)
query_output <-
jsonlite::fromJSON(paste0(srch_trm, "&offset=", i))
query_output
query_output$count
srch_trm
srch_trm <-  paste0(
"https://api.gbif.org/v1/occurrence/search?limit=300&","species=",term,"&media_type=",
if (type == "Sound")
"Sound" else if (type == "InteractiveResource")
"InteractiveResource" else if (type == "StillImage")
"StillImage" else
"MovingImage"
)
srch_trm
base.srch.pth <- rjson::fromJSON(file = srch_trm)
base.srch.pth$count\
base.srch.pth$count
# set dataset id
dataset_key <- "dataset_key=8a863029-f435-446a-821e-275f4f641165"
rm(ls = list())
rm(list = ls())
source("~/Documentos/GitHub/suwo/R/query_gbif.R")
source("~/Documentos/GitHub/suwo/R/internal_functions.R")
term <- "Turdus merula"
